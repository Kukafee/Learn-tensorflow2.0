{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从7011中保存的generator参数中恢复模型，并生成图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import multiprocessing\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "# scipy1.3.0  中没有 scipy.misc.toimage 方法，scipy1.0.0 中有，可以安装指定版本\n",
    "from scipy.misc import toimage  # scipy.misc 中缺少toimage方法，用PIL中的Image.fromarray代替\n",
    "from PIL import Image \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ConfigProto()   \n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "tf.random.set_seed(22)\n",
    "np.random.seed(22)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "assert tf.__version__.startswith('2.')\n",
    "assert np.__version__.startswith('1.16.2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义生成器G   向量[b, 100] => 图片[b, 81, 81, 3]\n",
    "class Generator(keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        # 输入一个向量，经过生成器，变成一个图片，图片逐渐变大，通道数不断减少\n",
    "        # z:[b, 100] => [b, 3*3*512]  全连接层        \n",
    "        self.fc = layers.Dense(3*3*512)\n",
    "        \n",
    "        # [b, 3, 3, 512] => [b, 9, 9, 256]   反卷积层(输出通道数_卷积核数量；核的大小；步长；padding)\n",
    "        # Conv2DTranspose 是考虑什么样的feature_map通过这个卷积层变成了现在的feature_map\n",
    "        self.conv1 = layers.Conv2DTranspose(256, 3, 3, 'valid')\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        # [b, 9, 9, 256] => [b, 29, 29, 128]  此处不是[b, 27, 27, 128]可能是因为受卷积核大小的影响吧\n",
    "        self.conv2 = layers.Conv2DTranspose(128, 5, 3, 'valid')\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "        # [b, 29, 29, 128] => [b, 88, 88, 3]\n",
    "        self.conv3 = layers.Conv2DTranspose(3, 4, 3, 'valid')\n",
    "        \n",
    "        \n",
    "    def call(self, inputs, training=None):\n",
    "        # [z, 100] => [z, 3*3*512]\n",
    "        x = self.fc(inputs)\n",
    "#         print(x.shape)\n",
    "        \n",
    "        # 获得图片feature_map\n",
    "        x = tf.reshape(x, [-1, 3, 3, 512])        \n",
    "        # 通过leaky_relu() 函数\n",
    "        x = tf.nn.leaky_relu(x)\n",
    "#         print(x.shape)\n",
    "        \n",
    "        # [b, 3, 3, 512] => [b, 9, 9, 256]\n",
    "        x = tf.nn.leaky_relu(self.bn1(self.conv1(x), training=training))\n",
    "#         print(x.shape)\n",
    "        \n",
    "        # [b, 9, 9, 256] => [b, 29, 29, 128]  因为卷积核比较大，是(5*5)所以得到是29*29\n",
    "        x = tf.nn.leaky_relu(self.bn2(self.conv2(x), training=training))\n",
    "#         print(x.shape)\n",
    "        \n",
    "        # [b, 29, 29, 128] => [b, 88, 88, 3]\n",
    "        x = self.conv3(x)\n",
    "        x = tf.tanh(x)\n",
    "        \n",
    "        return x    # [b, 88, 88, 3]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存图片的函数save_result()\n",
    "# save_result(fake_image.numpy(), 10, img_path, color_mode='P')    # [100, 88, 88, 3] 在 -1 到 1 之间\n",
    "def save_result(val_out, val_block_size, image_path, color_mode):\n",
    "    def preprocess(img):\n",
    "        img = ((img + 1.0) * 127.5).astype(np.uint8)    # 变换到（0， 255），再转换数据类型为np.uint8\n",
    "        # img = img.astype(np.uint8)\n",
    "        return img\n",
    "\n",
    "    preprocesed = preprocess(val_out)    # 获得经过preprocess()处理过的图片数据，在（0,255）之间     \n",
    "    single_row = np.array([])     # 定义一行\n",
    "    final_image = np.array([])    # 每次添加 single_row 一行的数据\n",
    "    for b in range(val_out.shape[0]):    # val_out.shape[0] = 100,一张一张处理图片；b = 0, 1, ... 99\n",
    "        # concat image into a row\n",
    "        if single_row.size == 0:\n",
    "            single_row = preprocesed[b, :, :, :] # preprocessed[0]表示第b张图片，并添加到single_row数组\n",
    "        else:\n",
    "            single_row = np.concatenate((single_row, preprocesed[b, :, :, :]), axis=1)\n",
    "\n",
    "        # concat image row to final_image\n",
    "        if (b+1) % val_block_size == 0:   # 每val_block_size（此处是10）张截取一行，当b=9时执行\n",
    "            if final_image.size == 0:    \n",
    "                final_image = single_row    # 把 single_row 中的数据拷贝至 final_image\n",
    "            else:    # axis=0 表示 每次添加一行图片数据\n",
    "                final_image = np.concatenate((final_image, single_row), axis=0)\n",
    "\n",
    "            # reset single row\n",
    "            single_row = np.array([])\n",
    "\n",
    "    if final_image.shape[2] == 1:    # 防止 final_image 出现 [10, 10, 1]情况，squeeze 高维度的1\n",
    "        final_image = np.squeeze(final_image, axis=2)\n",
    "    \n",
    "    toimage(final_image).save(image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded weights !\n"
     ]
    }
   ],
   "source": [
    "z_dim = 100\n",
    "r_generator = Generator()\n",
    "# 加载文件中的数据（保存有链接权重的数据）\n",
    "r_generator.load_weights('/home/kukafee/workspace/save_model/GAN/G_weight_30000.ckpt')\n",
    "# 打印信息\n",
    "print('Loaded weights !')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从平均分布中sample数据（训练的时候也是从正态分布中sample的随机数据）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kukafee/environments/tf2_py3/lib/python3.6/site-packages/ipykernel_launcher.py:32: DeprecationWarning: `toimage` is deprecated!\n",
      "`toimage` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use Pillow's ``Image.fromarray`` directly instead.\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    z = tf.random.uniform([100, z_dim])    # [100, 100]\n",
    "    fake_image = r_generator(z, training=False)    # [100, 88, 88, 3]\n",
    "    # '/home/kukafee/workspace/picture/GAN/fake_epoch_%d.png'%epoch\n",
    "    img_path = os.path.join('/home/kukafee/workspace/picture/R_GAN', 'fake_epoch_%d.png'%i)\n",
    "    save_result(fake_image.numpy(), 10, img_path, color_mode='P')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从高斯分布中sample数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kukafee/environments/tf2_py3/lib/python3.6/site-packages/ipykernel_launcher.py:32: DeprecationWarning: `toimage` is deprecated!\n",
      "`toimage` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use Pillow's ``Image.fromarray`` directly instead.\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    z = tf.random.normal([100, z_dim])    # [100, 100]\n",
    "    fake_image = r_generator(z, training=False)    # [100, 88, 88, 3]\n",
    "    # '/home/kukafee/workspace/picture/GAN/fake_epoch_%d.png'%epoch\n",
    "    img_path = os.path.join('/home/kukafee/workspace/picture/R_GAN', 'normal_fake_epoch_%d.png'%i)\n",
    "    save_result(fake_image.numpy(), 10, img_path, color_mode='P')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, optimizers, Sequential, metrics\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.2827 - accuracy: 0.8368\n",
      "Epoch 2/3\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1388 - accuracy: 0.9576 - val_loss: 0.1470 - val_accuracy: 0.9622\n",
      "Epoch 3/3\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1168 - accuracy: 0.9662\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1222 - accuracy: 0.9697\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.12223819872663545, 0.9697]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess(x, y):\n",
    "    \"\"\"x is a simple image, not a batch\"\"\"\n",
    "    x = tf.cast(x, dtype=tf.float32) / 255.\n",
    "    x = tf.reshape(x, [28*28])\n",
    "    y = tf.cast(y, dtype=tf.int32)\n",
    "    y = tf.one_hot(y, depth=10)\n",
    "    return x, y\n",
    "\n",
    "batchsz = 128\n",
    "(x, y), (x_val, y_val) = datasets.mnist.load_data()\n",
    "# print('datasets:', x.shape, y.shape, x.min(), y.min())\n",
    "\n",
    "db = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "db = db.map(preprocess).shuffle(60000).batch(batchsz)\n",
    "ds_val = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "ds_val = ds_val.map(preprocess).batch(batchsz)\n",
    "\n",
    "class MyDense(layers.Layer):\n",
    "    def __init__(self, inp_dim, outp_dim):\n",
    "        super(MyDense, self).__init__()\n",
    "        self.kernel = self.add_variable('w',[inp_dim, outp_dim])\n",
    "        self.bias = self.add_variable('b', [outp_dim])\n",
    "    def call(self, inputs, training=None):\n",
    "        out = inputs @ self.kernel + self.bias\n",
    "        return out\n",
    "    \n",
    "class MyModel(keras.Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.fc1 = MyDense(28*28, 256)\n",
    "        self.fc2 = MyDense(256, 128)\n",
    "        self.fc3 = MyDense(128, 64)\n",
    "        self.fc4 = MyDense(64, 32)\n",
    "        self.fc5 = MyDense(32, 10)\n",
    "    def call(self, inputs, training=None):\n",
    "        x = self.fc1(inputs)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.fc4(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.fc5(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "# 创建神经网络 network\n",
    "network = MyModel()\n",
    "network.compile(optimizer=optimizers.Adam(lr=0.01),\n",
    "               loss=tf.losses.CategoricalCrossentropy(from_logits=True),\n",
    "               metrics=['accuracy'])\n",
    "network.fit(db, epochs=3, validation_data=ds_val, validation_freq=2)\n",
    "network.evaluate(ds_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 保存 network 的参数到文件weights1.ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved weights !\n",
      "Loaded weights !\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.1298 - accuracy: 0.9582\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.12983709347251615, 0.9636]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 保存 network 的******参数******到文件\n",
    "network.save_weights('/home/kukafee/workspace/save_model/weights1.ckpt')\n",
    "# 打印信息\n",
    "print('Saved weights !')\n",
    "# 删除网络\n",
    "del network\n",
    "# 重新创建神经网络\n",
    "network = MyModel()\n",
    "network.compile(optimizer=optimizers.Adam(lr=0.01),\n",
    "               loss=tf.losses.CategoricalCrossentropy(from_logits=True),\n",
    "               metrics=['accuracy'])\n",
    "# 加载文件中的数据（保存有链接权重的数据）\n",
    "network.load_weights('/home/kukafee/workspace/save_model/weights1.ckpt')\n",
    "# 打印信息\n",
    "print('Loaded weights !')\n",
    "network.evaluate(ds_val)\n",
    "# 获得 evaluate 的两个属性\n",
    "# loss, acc = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 保存 network1 的所有信息到文件model.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_65 (Dense)             multiple                  200960    \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             multiple                  32896     \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             multiple                  8256      \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             multiple                  2080      \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             multiple                  330       \n",
      "=================================================================\n",
      "Total params: 244,522\n",
      "Trainable params: 244,522\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2765 - accuracy: 0.8396\n",
      "Epoch 2/3\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1373 - accuracy: 0.9576 - val_loss: 0.1350 - val_accuracy: 0.9631\n",
      "Epoch 3/3\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1103 - accuracy: 0.9679\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1216 - accuracy: 0.9659\n",
      "Saved total model !\n",
      "Load model from file:\n",
      "Loaded the model from file !\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-c2b780a46457>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;31m# y_val = tf.one_hot(y_val, depth=10)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;31m# network1.evaluate(x_val, y_val)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0mnetwork1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0mnetwork1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_val\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# 上面5行注释的代码可以实现同样功能\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0mnetwork1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environments/tf2_py3/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[1;32m   1575\u001b[0m     \"\"\"\n\u001b[1;32m   1576\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1577\u001b[0;31m       raise ValueError('This model has not yet been built. '\n\u001b[0m\u001b[1;32m   1578\u001b[0m                        \u001b[0;34m'Build the model first by calling `build()` or calling '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1579\u001b[0m                        \u001b[0;34m'`fit()` with some data, or specify '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build."
     ]
    }
   ],
   "source": [
    "def preprocess(x, y):\n",
    "    \"\"\"x is a simple image, not a batch\"\"\"\n",
    "    x = tf.cast(x, dtype=tf.float32) / 255.\n",
    "    x = tf.reshape(x, [28*28])\n",
    "    y = tf.cast(y, dtype=tf.int32)\n",
    "    y = tf.one_hot(y, depth=10)\n",
    "    return x, y\n",
    "\n",
    "batchsz = 128\n",
    "(x, y), (x_val, y_val) = datasets.mnist.load_data()\n",
    "# print('datasets:', x.shape, y.shape, x.min(), y.min())\n",
    "\n",
    "db = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "db = db.map(preprocess).shuffle(60000).batch(batchsz)\n",
    "ds_val = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "ds_val = ds_val.map(preprocess).batch(batchsz)\n",
    "\n",
    "network1 = Sequential([   \n",
    "    layers.Dense(256, activation=tf.nn.relu),    # [b, 784] => [b, 256]\n",
    "    layers.Dense(128, activation=tf.nn.relu),    # [b, 256] => [b, 128]\n",
    "    layers.Dense(64, activation=tf.nn.relu),     # [b, 128] => [b, 64]\n",
    "    layers.Dense(32, activation=tf.nn.relu),     # [b, 64] => [b, 32]\n",
    "    layers.Dense(10)                             # [b, 32] => [b, 10]\n",
    "])\n",
    "network1.build(input_shape=(None, 28*28))\n",
    "network1.summary()\n",
    "# 创建神经网络 network\n",
    "network1.compile(optimizer=optimizers.Adam(lr=0.01),\n",
    "               loss=tf.losses.CategoricalCrossentropy(from_logits=True),\n",
    "               metrics=['accuracy'])\n",
    "network1.fit(db, epochs=3, validation_data=ds_val, validation_freq=2)\n",
    "network1.evaluate(ds_val)\n",
    "\n",
    "\n",
    "# 保存 network 的******所有信息******到文件，下面两行代码任选其一即可：\n",
    "# tf.keras.models.save_model(network1, '/home/kukafee/workspace/save_model/entire_model6173/model.h5')\n",
    "network1.save('/home/kukafee/workspace/save_model/entire_model6173/model.h5')\n",
    "\n",
    "print('Saved total model !')\n",
    "del network1\n",
    "print('Load model from file:')\n",
    "network1 = tf.keras.models.load_model('/home/kukafee/workspace/save_model/entire_model6173/model.h5', \n",
    "                                     compile=False)\n",
    "network1.compile(optimizer=optimizers.Adam(lr=0.01),\n",
    "               loss=tf.losses.CategoricalCrossentropy(from_logits=True),\n",
    "               metrics=['accuracy'])\n",
    "print('Loaded the model from file !')\n",
    "# network1.summary()   # 此行代码无法在此执行\n",
    "\n",
    "# x_val = tf.cast(x_val, dtype=tf.float32) / 255.\n",
    "# x_val = tf.reshape(x_val, [-1, 28*28])\n",
    "# y_val = tf.cast(y_val, dtype=tf.int32)\n",
    "# y_val = tf.one_hot(y_val, depth=10)\n",
    "# network1.evaluate(x_val, y_val)\n",
    "\n",
    "network1.evaluate(ds_val)    # 上面5行注释的代码可以实现同样功能\n",
    "network1.summary()   # 可以执行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

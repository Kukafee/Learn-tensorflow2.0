{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GAN与WGAN在实现时，只有在train的时候部分代码需要改动"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import multiprocessing\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "from scipy.misc import toimage\n",
    "from PIL import Image \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ConfigProto()   \n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "tf.random.set_seed(22)\n",
    "np.random.seed(22)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "assert tf.__version__.startswith('2.')\n",
    "assert np.__version__.startswith('1.16.2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义生成器G   向量[b, 100] => 图片[b, 81, 81, 3]\n",
    "class Generator(keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        # 输入一个向量，经过生成器，变成一个图片，图片逐渐变大，通道数不断减少\n",
    "        # z:[b, 100] => [b, 3*3*512]  全连接层        \n",
    "        self.fc = layers.Dense(3*3*512)\n",
    "        \n",
    "        # [b, 3, 3, 512] => [b, 9, 9, 256]   反卷积层(输出通道数_卷积核数量；核的大小；步长；padding)\n",
    "        # Conv2DTranspose 是考虑什么样的feature_map通过这个卷积层变成了现在的feature_map\n",
    "        self.conv1 = layers.Conv2DTranspose(256, 3, 3, 'valid')\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        # [b, 9, 9, 256] => [b, 29, 29, 128]  此处不是[b, 27, 27, 128]可能是因为受卷积核大小的影响吧\n",
    "        self.conv2 = layers.Conv2DTranspose(128, 5, 3, 'valid')\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "        # [b, 29, 29, 128] => [b, 88, 88, 3]\n",
    "        self.conv3 = layers.Conv2DTranspose(3, 4, 3, 'valid')\n",
    "        \n",
    "        \n",
    "    def call(self, inputs, training=None):\n",
    "        # [z, 100] => [z, 3*3*512]\n",
    "        x = self.fc(inputs)\n",
    "        # 获得图片feature_map\n",
    "        x = tf.reshape(x, [-1, 3, 3, 512])        \n",
    "        # 通过leaky_relu() 函数\n",
    "        x = tf.nn.leaky_relu(x)\n",
    "        # [b, 3, 3, 512] => [b, 9, 9, 256]\n",
    "        x = tf.nn.leaky_relu(self.bn1(self.conv1(x), training=training))\n",
    "        # [b, 9, 9, 256] => [b, 29, 29, 128]  因为卷积核比较大，是(5*5)所以得到是29*29\n",
    "        x = tf.nn.leaky_relu(self.bn2(self.conv2(x), training=training))\n",
    "        # [b, 29, 29, 128] => [b, 88, 88, 3]\n",
    "        x = self.conv3(x)\n",
    "        x = tf.tanh(x)       \n",
    "        return x    # [b, 88, 88, 3]\n",
    "    \n",
    "    \n",
    "# 定义判别器D  图片[b, 81, 81, 3] => 向量[b, 1]\n",
    "class Discriminator(keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        # [b, 81, 81, 3] => [b, 27, 27, 64]\n",
    "        self.conv1 = layers.Conv2D(64, 5, 3, 'valid')\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        # [b, 27, 27, 64] => [b, 9, 9, 128]\n",
    "        self.conv2 = layers.Conv2D(128, 5, 3, 'valid')\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "        # [b, 9, 9, 128] => [b, 3, 3, 256]\n",
    "        self.conv3 = layers.Conv2D(256, 5, 3, 'valid')\n",
    "        self.bn3 = layers.BatchNormalization()\n",
    "        \n",
    "        # [b, 3, 3, 256] => [b, -1]\n",
    "        # 调用 layers.Flatten() 函数\n",
    "        self.flatten = layers.Flatten()\n",
    "        # 通过一个全连接层，输出节点数为1\n",
    "        self.fc = layers.Dense(1)\n",
    "        \n",
    "    def call(self, inputs, training=None):\n",
    "        x = tf.nn.leaky_relu(self.bn1(self.conv1(inputs), training=training))\n",
    "        x = tf.nn.leaky_relu(self.bn2(self.conv2(x), training=training))\n",
    "        x = tf.nn.leaky_relu(self.bn3(self.conv3(x), training=training))\n",
    "        x = self.flatten(x)\n",
    "        logits = self.fc(x)\n",
    "        \n",
    "        return logits    # [b, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_result(val_out, val_block_size, image_path, color_mode):\n",
    "    def preprocess(img):\n",
    "        img = ((img + 1.0) * 127.5).astype(np.uint8)    # 变换到（0， 255），再转换数据类型为np.uint8\n",
    "        # img = img.astype(np.uint8)\n",
    "        return img\n",
    "\n",
    "    preprocesed = preprocess(val_out)    # 获得经过preprocess()处理过的图片数据，在（0,255）之间     \n",
    "    single_row = np.array([])     # 定义一行\n",
    "    final_image = np.array([])    # 每次添加 single_row 一行的数据\n",
    "    for b in range(val_out.shape[0]):    # val_out.shape[0] = 100,一张一张处理图片；b = 0, 1, ... 99\n",
    "        # concat image into a row\n",
    "        if single_row.size == 0:\n",
    "            single_row = preprocesed[b, :, :, :] # preprocessed[0]表示第b张图片，并添加到single_row数组\n",
    "        else:\n",
    "            single_row = np.concatenate((single_row, preprocesed[b, :, :, :]), axis=1)\n",
    "\n",
    "        # concat image row to final_image\n",
    "        if (b+1) % val_block_size == 0:   # 每val_block_size（此处是10）张截取一行，当b=9时执行\n",
    "            if final_image.size == 0:    \n",
    "                final_image = single_row    # 把 single_row 中的数据拷贝至 final_image\n",
    "            else:    # axis=0 表示 每次添加一行图片数据\n",
    "                final_image = np.concatenate((final_image, single_row), axis=0)\n",
    "\n",
    "            # reset single row\n",
    "            single_row = np.array([])\n",
    "\n",
    "    if final_image.shape[2] == 1:    # 防止 final_image 出现 [10, 10, 1]情况，squeeze 高维度的1\n",
    "        final_image = np.squeeze(final_image, axis=2)\n",
    "    \n",
    "    toimage(final_image).save(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义 make_anime_dataset()  用于获取anime数据集中的每一张图片\n",
    "def make_anime_dataset(img_paths, batch_size, resize=88, drop_remainder=True, shuffle=True, repeat=1):\n",
    "    @tf.function\n",
    "    def _map_fn(img):\n",
    "        img = tf.image.resize(img, [resize, resize])\n",
    "        img = tf.clip_by_value(img, 0, 255)\n",
    "        img = img / 127.5 - 1\n",
    "        return img\n",
    "\n",
    "    dataset = disk_image_batch_dataset(img_paths,\n",
    "                                          batch_size,\n",
    "                                          drop_remainder=drop_remainder,\n",
    "                                          map_fn=_map_fn,\n",
    "                                          shuffle=shuffle,\n",
    "                                          repeat=repeat)\n",
    "    img_shape = (resize, resize, 3)\n",
    "    len_dataset = len(img_paths) // batch_size\n",
    "\n",
    "    return dataset, img_shape, len_dataset\n",
    "\n",
    "\n",
    "def batch_dataset(dataset,\n",
    "                  batch_size,\n",
    "                  drop_remainder=True,\n",
    "                  n_prefetch_batch=1,\n",
    "                  filter_fn=None,\n",
    "                  map_fn=None,\n",
    "                  n_map_threads=None,\n",
    "                  filter_after_map=False,\n",
    "                  shuffle=True,\n",
    "                  shuffle_buffer_size=None,\n",
    "                  repeat=None):\n",
    "    # set defaults\n",
    "    if n_map_threads is None:\n",
    "        n_map_threads = multiprocessing.cpu_count()\n",
    "    if shuffle and shuffle_buffer_size is None:\n",
    "        shuffle_buffer_size = max(batch_size * 128, 2048)  # set the minimum buffer size as 2048\n",
    "\n",
    "    # [*] it is efficient to conduct `shuffle` before `map`/`filter` because `map`/`filter` \n",
    "    # is sometimes costly\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(shuffle_buffer_size)\n",
    "\n",
    "    if not filter_after_map:\n",
    "        if filter_fn:\n",
    "            dataset = dataset.filter(filter_fn)\n",
    "\n",
    "        if map_fn:\n",
    "            dataset = dataset.map(map_fn, num_parallel_calls=n_map_threads)\n",
    "\n",
    "    else:  # [*] this is slower\n",
    "        if map_fn:\n",
    "            dataset = dataset.map(map_fn, num_parallel_calls=n_map_threads)\n",
    "\n",
    "        if filter_fn:\n",
    "            dataset = dataset.filter(filter_fn)\n",
    "\n",
    "    dataset = dataset.batch(batch_size, drop_remainder=drop_remainder)\n",
    "\n",
    "    dataset = dataset.repeat(repeat).prefetch(n_prefetch_batch)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def memory_data_batch_dataset(memory_data,\n",
    "                              batch_size,\n",
    "                              drop_remainder=True,\n",
    "                              n_prefetch_batch=1,\n",
    "                              filter_fn=None,\n",
    "                              map_fn=None,\n",
    "                              n_map_threads=None,\n",
    "                              filter_after_map=False,\n",
    "                              shuffle=True,\n",
    "                              shuffle_buffer_size=None,\n",
    "                              repeat=None):\n",
    "    \"\"\"Batch dataset of memory data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    memory_data : nested structure of tensors/ndarrays/lists\n",
    "\n",
    "    \"\"\"\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(memory_data)\n",
    "    dataset = batch_dataset(dataset,\n",
    "                            batch_size,\n",
    "                            drop_remainder=drop_remainder,\n",
    "                            n_prefetch_batch=n_prefetch_batch,\n",
    "                            filter_fn=filter_fn,\n",
    "                            map_fn=map_fn,\n",
    "                            n_map_threads=n_map_threads,\n",
    "                            filter_after_map=filter_after_map,\n",
    "                            shuffle=shuffle,\n",
    "                            shuffle_buffer_size=shuffle_buffer_size,\n",
    "                            repeat=repeat)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def disk_image_batch_dataset(img_paths,\n",
    "                             batch_size,\n",
    "                             labels=None,\n",
    "                             drop_remainder=True,\n",
    "                             n_prefetch_batch=1,\n",
    "                             filter_fn=None,\n",
    "                             map_fn=None,\n",
    "                             n_map_threads=None,\n",
    "                             filter_after_map=False,\n",
    "                             shuffle=True,\n",
    "                             shuffle_buffer_size=None,\n",
    "                             repeat=None):\n",
    "    \"\"\"Batch dataset of disk image for PNG and JPEG.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        img_paths : 1d-tensor/ndarray/list of str\n",
    "        labels : nested structure of tensors/ndarrays/lists\n",
    "\n",
    "    \"\"\"\n",
    "    if labels is None:\n",
    "        memory_data = img_paths\n",
    "    else:\n",
    "        memory_data = (img_paths, labels)\n",
    "\n",
    "    def parse_fn(path, *label):\n",
    "        img = tf.io.read_file(path)\n",
    "        img = tf.image.decode_png(img, 3)  # fix channels to 3\n",
    "        return (img,) + label\n",
    "\n",
    "    if map_fn:  # fuse `map_fn` and `parse_fn`\n",
    "        def map_fn_(*args):\n",
    "            return map_fn(*parse_fn(*args))\n",
    "    else:\n",
    "        map_fn_ = parse_fn\n",
    "\n",
    "    dataset = memory_data_batch_dataset(memory_data,\n",
    "                                        batch_size,\n",
    "                                        drop_remainder=drop_remainder,\n",
    "                                        n_prefetch_batch=n_prefetch_batch,\n",
    "                                        filter_fn=filter_fn,\n",
    "                                        map_fn=map_fn_,\n",
    "                                        n_map_threads=n_map_threads,\n",
    "                                        filter_after_map=filter_after_map,\n",
    "                                        shuffle=shuffle,\n",
    "                                        shuffle_buffer_size=shuffle_buffer_size,\n",
    "                                        repeat=repeat)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义 loss_ones()函数，logits 与 [1, 1, 1, ..., 1] 之间的误差\n",
    "def loss_ones(logits):\n",
    "    # [b, 1]  VS. [b] = [1, 1, ... , 1]\n",
    "    loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=tf.ones_like(logits))\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "# 定义 loss_zeros()函数，logits 与 [0, 0, 0, ..., 0] 之间的误差\n",
    "def loss_zeros(logits):\n",
    "    loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=tf.zeros_like(logits))\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "#  **********************  WAN  *****************************************\n",
    "# 定义惩罚项gradient_penalty() 函数，这是WGAN特有的\n",
    "# gp_loss = gradient_penalty(discriminator, batch_x, batch_x_hat)\n",
    "def gradient_penalty(discriminator, batch_x, batch_x_hat):\n",
    "    batchsz = batch_x.shape[0]  \n",
    "    # [b, 1, 1, 1]\n",
    "    t = tf.random.uniform([batchsz, 1, 1, 1])\n",
    "    # [b, 1, 1, 1] => [b, h, w, c]\n",
    "    t = tf.broadcast_to(t, batch_x.shape)\n",
    "    #定义中间变量\n",
    "    interplate = t * batch_x + (1. - t) * batch_x_hat\n",
    "    # 计算梯度\n",
    "    with tf.GradientTape() as tape:\n",
    "        # 因为 interplate 只是 tensor 类型，需要使用tape.watch()读取，若是variable类型，则不需要\n",
    "        tape.watch([interplate])\n",
    "        d_interplate_logits = discriminator(interplate)\n",
    "    grads = tape.gradient(d_interplate_logits, interplate)\n",
    "    # 打平操作\n",
    "    # grads [b, h, w, c] => [b, -1]\n",
    "    grads = tf.reshape(grads, [grads.shape[0], -1])\n",
    "    # 计算范数值\n",
    "    grads_norm = tf.norm(grads, axis=1)  # [b]\n",
    "    # 计算范数的均值\n",
    "    grads_norm_mean = tf.reduce_mean((grads_norm-1) ** 2)\n",
    "    \n",
    "    return grads_norm_mean\n",
    "\n",
    "#  **********************  WGAN  *****************************************\n",
    "# 定义计算判别器discriminator的损失函数d_loss_fn()\n",
    "# d_loss = d_loss_fn(generator, discriminator, batch_z, batch_x, is_training)\n",
    "def d_loss_fn(generator, discriminator, batch_z, batch_x, is_training):\n",
    "    # treat real image as real 对于真实的图片数据\n",
    "    d_real_logits = discriminator(batch_x, is_training)\n",
    "    # treat generated image as fake 对于生成的图片数据\n",
    "    batch_x_hat = generator(batch_z, is_training)\n",
    "    d_fake_logits = discriminator(batch_x_hat, is_training)\n",
    "    # 计算真实图片的损失\n",
    "    d_loss_real = loss_ones(d_real_logits)\n",
    "    # 计算生成图片的损失（fake）\n",
    "    d_loss_fake = loss_zeros(d_fake_logits)    \n",
    "    # *************************************  WGAN  *********************************** d_loss_fn\n",
    "    \n",
    "    gp_loss = gradient_penalty(discriminator, batch_x, batch_x_hat)\n",
    "    # 设置平衡因子，大致可设置为 1. 到 10. 左右，需要手动调节\n",
    "    lamda = 1.\n",
    "    loss = d_loss_real + d_loss_fake + gp_loss * lamda\n",
    "    \n",
    "    return loss, gp_loss\n",
    "    # *************************************  WGAN  ***********************************\n",
    "    \n",
    "# 定义计算生成器generator的损失函数\n",
    "# g_loss = g_loss_fn(generator, discriminator, batch_z, is_training):\n",
    "def g_loss_fn(generator, discriminator, batch_z, is_training):\n",
    "    d_fake_logits = discriminator(generator(batch_z, is_training), is_training)\n",
    "    g_loss_fake = loss_ones(d_fake_logits)    \n",
    "    return g_loss_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义输入到生成器的向量维度\n",
    "z_dim = 100    # z[b, 100] => x_hat[b, 88, 88, 3] => x_hat_pro[b, 1]\n",
    "# 定义训练世代数\n",
    "epochs = 3000000  # 三百万次\n",
    "# epochs = 200\n",
    "# 定义批处理数据大小\n",
    "# batch_size = 1024\n",
    "batch_size = 768\n",
    "# 定义学习率\n",
    "learning_rate = 2e-3\n",
    "# 定义训练参数\n",
    "is_training = True\n",
    "# 定义数据集中图片的路径\n",
    "#返回所有匹配的文件路径列表。它只有一个参数pathname，定义了文件路径匹配规则\n",
    "img_path = glob.glob('/home/kukafee/shared/faces/*.jpg')\n",
    "# 获取数据集中每批次的数据\n",
    "dataset, img_shape, _ = make_anime_dataset(img_path, batch_size)\n",
    "# print(dataset, img_shape) # <PrefetchDataset shapes: (512, 88, 88, 3), types: tf.float32> (88, 88, 3)\n",
    "# 构建迭代器，并查看其中的元素\n",
    "# sample = next(iter(dataset))\n",
    "# print(sample.shape, tf.reduce_max(sample).numpy(), tf.reduce_min(sample).numpy())\n",
    "# 使得可迭代对象可循环\n",
    "dataset = dataset.repeat()\n",
    "db_iter = iter(dataset)    # 构建迭代器 db_iter\n",
    "\n",
    "# 定义并构建生成器网络\n",
    "generator = Generator()\n",
    "generator.build(input_shape = (None, z_dim))\n",
    "# generator.summary()\n",
    "# 定义并构建判别器网络\n",
    "discriminator = Discriminator()\n",
    "discriminator.build(input_shape = (None, 88, 88, 3))\n",
    "# discriminator.summary()\n",
    "# 定义优化器 \n",
    "# 其中参数 beta_1: A float value or a constant float tensor. The exponential decay rate for the 1st\n",
    "# moment estimates.\n",
    "g_optimizer = tf.optimizers.Adam(learning_rate=learning_rate, beta_1=0.5)\n",
    "d_optimizer = tf.optimizers.Adam(learning_rate=learning_rate, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练并测试GAN\n",
    "def main():\n",
    "    # 循环每一个世代\n",
    "    for epoch in range(epochs):\n",
    "        # 定义一批要送入生成器的随机均匀分布数据\n",
    "        # z[b, 100] => x_hat[b, 88, 88, 3] => x_hat_pro[b, 1]\n",
    "        batch_z = tf.random.uniform([batch_size, z_dim], minval=-1., maxval=1.)\n",
    "        # 从迭代器 db_iter 中生成要送入判别器的图片数据\n",
    "        batch_x = next(db_iter)\n",
    "        for i in range(2):            \n",
    "            # 训练判别器D——discriminator\n",
    "            with tf.GradientTape() as tape:\n",
    "                d_loss, dg_loss = d_loss_fn(generator, discriminator, batch_z, batch_x, is_training)\n",
    "            # 计算梯度\n",
    "            grads = tape.gradient(d_loss, discriminator.trainable_variables)\n",
    "            # 更新参数\n",
    "            d_optimizer.apply_gradients(zip(grads, discriminator.trainable_variables))\n",
    "                \n",
    "        # 训练生成器G——generator\n",
    "        with tf.GradientTape() as tape:\n",
    "            g_loss = g_loss_fn(generator, discriminator, batch_z, is_training)\n",
    "        grads = tape.gradient(g_loss, generator.trainable_variables)\n",
    "        g_optimizer.apply_gradients(zip(grads, generator.trainable_variables))\n",
    "        \n",
    "        \n",
    "        if epoch % 100 == 0:    # *************GAN*********添加gp_loss的显示，该值应该接近于0\n",
    "            print(epoch, 'd-loss: ', float(d_loss), 'g-loss: ', float(g_loss), 'dg_loss', float(dg_loss))\n",
    "            \n",
    "            # 测试生气器网络效果\n",
    "            # 从正态分布中随机产生数据\n",
    "            z = tf.random.uniform([100, z_dim])    # [100, 100]\n",
    "            fake_image = generator(z, training=False)    # [100, 88, 88, 3]\n",
    "            # '/home/kukafee/workspace/picture/GAN/fake_epoch_%d.png'%epoch\n",
    "            img_path = os.path.join('/home/kukafee/workspace/picture/WGAN', 'fake_epoch_%d.png'%epoch)\n",
    "            save_result(fake_image.numpy(), 10, img_path, color_mode='P')\n",
    "            \n",
    "        if epoch % 1000 == 0:            \n",
    "            # 保存 network 的******参数******到文件\n",
    "            generator.save_weights('/home/kukafee/workspace/save_model/WGAN/G_weight_%d.ckpt'%epoch)\n",
    "            discriminator.save_weights('/home/kukafee/workspace/save_model/WGAN/D_weight_%d.ckpt'%epoch)\n",
    "            # 打印信息\n",
    "            print('Saved G&D_weights: %d'%epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练了514分钟；模型参数最新保存至Saved G&D_weights: 37000\n",
    "###### 37000 d-loss:  1.3720537424087524 g-loss:  0.7379453778266907 dg_loss 0.0009328257292509079\n",
    "###### Saved G&D_weights: 37000\n",
    "###### 37100 d-loss:  1.376948595046997 g-loss:  0.7198958992958069 dg_loss 0.0010607395088300109\n",
    "###### 37200 d-loss:  1.3777310848236084 g-loss:  0.7109716534614563 dg_loss 0.000748057325836271\n",
    "###### 37300 d-loss:  1.3667497634887695 g-loss:  0.7310948967933655 dg_loss 0.0010721470462158322"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

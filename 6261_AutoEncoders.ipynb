{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto Encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential, layers\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义随机种子和验证TensorFlow的版本\n",
    "tf.random.set_seed(22)\n",
    "np.random.seed(22)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "assert tf.__version__.startswith('2.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义保存图片的函数save_image(image, name)，将多张图片保存到一张图片中\n",
    "# images 表示\n",
    "# name 表示\n",
    "def save_images(imgs, name):\n",
    "    # Image : Creates a new image with the given mode and size.创建一个新图片\n",
    "    # Image.new(mode, size, color=0)\n",
    "    new_im = Image.new('L', (280, 280))\n",
    "    \n",
    "    index = 0\n",
    "    for i in range(0, 280, 28):    # range(start, stop[, step])\n",
    "        for j in range(0, 280, 28):\n",
    "            im = imgs[index]    # 根据索引获取图片\n",
    "            im = Image.fromarray(im, mode='L')    # 实现im（数组类型）array到（图片）image类型的转换\n",
    "            new_im.paste(im, (i, j))    # 将im paste 到(i, j) 的位置\n",
    "            index += 1    # 索引值累加\n",
    "    new_im.save(name)   # 保存 new_im 到指定的路径下的文件[name 参数需指定path & file_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 定义超参数（超参数需要人工调整）注意：在这里定义的是全局变量\n",
    "# 通过AutoEncoders 将图片降维后的维度\n",
    "h_dim = 20\n",
    "# 定义批处理数量\n",
    "batchsz = 512\n",
    "# 定义学习率\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n",
      "(10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "# 加载数据集并预处理\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "# print(type(x_train))\n",
    "# print(type(y_train))\n",
    "# 此处不要标签数据，只需要x_train 和 x_test\n",
    "# astype() 完成数据类型转换\n",
    "x_train, x_test = x_train.astype(np.float32) / 255., x_test.astype(np.float32) / 255.\n",
    "train_db = tf.data.Dataset.from_tensor_slices(x_train)\n",
    "train_db = train_db.shuffle(batchsz * 5).batch(batchsz)\n",
    "test_db = tf.data.Dataset.from_tensor_slices(x_test)\n",
    "# test_db = test_db.batch(batchsz)\n",
    "test_db = test_db.batch(50)\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"auto_encoders_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_2 (Sequential)    multiple                  236436    \n",
      "_________________________________________________________________\n",
      "sequential_3 (Sequential)    multiple                  237200    \n",
      "=================================================================\n",
      "Total params: 473,636\n",
      "Trainable params: 473,636\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 定义AutoEncoers类，用于对图片数据的处理\n",
    "class AutoEncoders(keras.Model):\n",
    "    def __init__(self):    # 不需要传递 h_dim 参数，因为这个参数是全局变量\n",
    "        super(AutoEncoders, self).__init__()\n",
    "        \n",
    "        # Encoders层\n",
    "        self.encoder = Sequential([\n",
    "            layers.Dense(256, activation=tf.nn.relu),    # [b, 28*28] => [b, 256]\n",
    "            layers.Dense(128, activation=tf.nn.relu),    # [b, 256] => [b, 128]\n",
    "            layers.Dense(h_dim)                          # [b, 128] => [b, h_dim]\n",
    "        ])\n",
    "    \n",
    "        # Decoders 层\n",
    "        self.decoder = Sequential([\n",
    "            layers.Dense(128, activation=tf.nn.relu),    # [b, h_dim] => [b, 128]\n",
    "            layers.Dense(256, activation=tf.nn.relu),    # [b, 128] => [b, 256]\n",
    "            layers.Dense(28*28)                          # [b, 256] => [b, 28*28]\n",
    "        ])\n",
    "    \n",
    "    # 定义call方法，实现前向传播\n",
    "    def call(self, inputs, training=None):\n",
    "        h = self.encoder(inputs)    # [b, 28*28] => [b, 20]\n",
    "        x_hat = self.decoder(h)     # [b, 20] => [b, 28*28]\n",
    "        \n",
    "        return x_hat\n",
    "    \n",
    "# 定义AutoEncoers类实例\n",
    "autoEncoder = AutoEncoders()\n",
    "# 调用 build()方法，需要传递input_shape参数，指定输入数据的维度\n",
    "autoEncoder.build(input_shape=(None, 28*28))\n",
    "# 查看网络的 summary\n",
    "autoEncoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0.6926943063735962\n",
      "0 100 0.32506993412971497\n",
      "1 0 0.311957448720932\n",
      "1 100 0.30228668451309204\n",
      "2 0 0.2933153808116913\n",
      "2 100 0.2949793040752411\n",
      "3 0 0.28729984164237976\n",
      "3 100 0.2936669588088989\n",
      "4 0 0.28346970677375793\n",
      "4 100 0.28766804933547974\n",
      "5 0 0.28027844429016113\n",
      "5 100 0.28534072637557983\n",
      "6 0 0.27829572558403015\n",
      "6 100 0.2834666073322296\n",
      "7 0 0.2777024507522583\n",
      "7 100 0.28189289569854736\n",
      "8 0 0.2750740945339203\n",
      "8 100 0.28097739815711975\n",
      "9 0 0.2755848169326782\n",
      "9 100 0.27975577116012573\n",
      "10 0 0.27388712763786316\n",
      "10 100 0.2793492078781128\n",
      "11 0 0.27210408449172974\n",
      "11 100 0.27822038531303406\n",
      "12 0 0.2713480293750763\n",
      "12 100 0.277967244386673\n",
      "13 0 0.27047988772392273\n",
      "13 100 0.2771189212799072\n",
      "14 0 0.26970478892326355\n",
      "14 100 0.2759568989276886\n",
      "15 0 0.2693599760532379\n",
      "15 100 0.27548521757125854\n",
      "16 0 0.26865154504776\n",
      "16 100 0.27515745162963867\n",
      "17 0 0.26814794540405273\n",
      "17 100 0.2743704319000244\n",
      "18 0 0.2678173780441284\n",
      "18 100 0.27387046813964844\n",
      "19 0 0.2672489285469055\n",
      "19 100 0.2740730047225952\n",
      "20 0 0.2669540047645569\n",
      "20 100 0.27315229177474976\n",
      "21 0 0.26690182089805603\n",
      "21 100 0.27290022373199463\n",
      "22 0 0.26640671491622925\n",
      "22 100 0.272478312253952\n",
      "23 0 0.26641419529914856\n",
      "23 100 0.27247151732444763\n",
      "24 0 0.26593148708343506\n",
      "24 100 0.27194690704345703\n",
      "25 0 0.2654660940170288\n",
      "25 100 0.2716570198535919\n",
      "26 0 0.265179306268692\n",
      "26 100 0.27135857939720154\n",
      "27 0 0.2648845613002777\n",
      "27 100 0.27114057540893555\n",
      "28 0 0.264708548784256\n",
      "28 100 0.2709103226661682\n",
      "29 0 0.2644950747489929\n",
      "29 100 0.27071043848991394\n",
      "30 0 0.2643067240715027\n",
      "30 100 0.27149733901023865\n",
      "31 0 0.26566314697265625\n",
      "31 100 0.27061429619789124\n",
      "32 0 0.26405924558639526\n",
      "32 100 0.2703934609889984\n",
      "33 0 0.263746440410614\n",
      "33 100 0.2701181471347809\n",
      "34 0 0.2634667754173279\n",
      "34 100 0.269862562417984\n",
      "35 0 0.2632371783256531\n",
      "35 100 0.26986533403396606\n",
      "36 0 0.26316559314727783\n",
      "36 100 0.27014023065567017\n",
      "37 0 0.26309633255004883\n",
      "37 100 0.26985660195350647\n",
      "38 0 0.2633025348186493\n",
      "38 100 0.2693379521369934\n",
      "39 0 0.26304396986961365\n",
      "39 100 0.269239217042923\n",
      "40 0 0.2633120119571686\n",
      "40 100 0.2691265344619751\n",
      "41 0 0.2629726529121399\n",
      "41 100 0.26896023750305176\n",
      "42 0 0.2627545893192291\n",
      "42 100 0.2687950134277344\n",
      "43 0 0.26249679923057556\n",
      "43 100 0.26866620779037476\n",
      "44 0 0.26218387484550476\n",
      "44 100 0.26873281598091125\n",
      "45 0 0.2619814872741699\n",
      "45 100 0.26847410202026367\n",
      "46 0 0.2619628608226776\n",
      "46 100 0.268340528011322\n",
      "47 0 0.26188039779663086\n",
      "47 100 0.2682541310787201\n",
      "48 0 0.26182040572166443\n",
      "48 100 0.2681944966316223\n",
      "49 0 0.26174449920654297\n",
      "49 100 0.26812881231307983\n",
      "50 0 0.2616802752017975\n",
      "50 100 0.2681518793106079\n",
      "51 0 0.26179373264312744\n",
      "51 100 0.268038809299469\n",
      "52 0 0.2614613175392151\n",
      "52 100 0.2684679925441742\n",
      "53 0 0.26159438490867615\n",
      "53 100 0.26831528544425964\n",
      "54 0 0.2621571123600006\n",
      "54 100 0.26780569553375244\n",
      "55 0 0.2617512345314026\n",
      "55 100 0.2678133547306061\n",
      "56 0 0.26148420572280884\n",
      "56 100 0.2677793502807617\n",
      "57 0 0.26112499833106995\n",
      "57 100 0.26768171787261963\n",
      "58 0 0.26104485988616943\n",
      "58 100 0.2675422132015228\n",
      "59 0 0.261009156703949\n",
      "59 100 0.26740580797195435\n",
      "60 0 0.26088178157806396\n",
      "60 100 0.2675120234489441\n",
      "61 0 0.2607728838920593\n",
      "61 100 0.26735439896583557\n",
      "62 0 0.2607293725013733\n",
      "62 100 0.26717451214790344\n",
      "63 0 0.2606588304042816\n",
      "63 100 0.26716357469558716\n",
      "64 0 0.2605762779712677\n",
      "64 100 0.26715531945228577\n",
      "65 0 0.26051726937294006\n",
      "65 100 0.26712295413017273\n",
      "66 0 0.26045626401901245\n",
      "66 100 0.26713797450065613\n",
      "67 0 0.260468989610672\n",
      "67 100 0.2671172320842743\n",
      "68 0 0.26039737462997437\n",
      "68 100 0.2670711576938629\n",
      "69 0 0.2605268657207489\n",
      "69 100 0.2669979929924011\n",
      "70 0 0.26032155752182007\n",
      "70 100 0.26763716340065\n",
      "71 0 0.26057422161102295\n",
      "71 100 0.26690199971199036\n",
      "72 0 0.2604812681674957\n",
      "72 100 0.26677805185317993\n",
      "73 0 0.2606176733970642\n",
      "73 100 0.2666374742984772\n",
      "74 0 0.2604871094226837\n",
      "74 100 0.26662111282348633\n",
      "75 0 0.26026493310928345\n",
      "75 100 0.2666087746620178\n",
      "76 0 0.2601151168346405\n",
      "76 100 0.26647430658340454\n",
      "77 0 0.2600429654121399\n",
      "77 100 0.2664264440536499\n",
      "78 0 0.2599697709083557\n",
      "78 100 0.2664303779602051\n",
      "79 0 0.25989067554473877\n",
      "79 100 0.2663971185684204\n",
      "80 0 0.2598247230052948\n",
      "80 100 0.2664898633956909\n",
      "81 0 0.25977668166160583\n",
      "81 100 0.26627615094184875\n",
      "82 0 0.2598642110824585\n",
      "82 100 0.26640188694000244\n",
      "83 0 0.25979405641555786\n",
      "83 100 0.2665119767189026\n",
      "84 0 0.2597990036010742\n",
      "84 100 0.26654794812202454\n",
      "85 0 0.2597526013851166\n",
      "85 100 0.2663984000682831\n",
      "86 0 0.26003754138946533\n",
      "86 100 0.266128808259964\n",
      "87 0 0.26013749837875366\n",
      "87 100 0.266460120677948\n",
      "88 0 0.2602982819080353\n",
      "88 100 0.2661362290382385\n",
      "89 0 0.2595784068107605\n",
      "89 100 0.26620975136756897\n",
      "90 0 0.2596234083175659\n",
      "90 100 0.26642268896102905\n",
      "91 0 0.2600293755531311\n",
      "91 100 0.2661583423614502\n",
      "92 0 0.2595742344856262\n",
      "92 100 0.2660335302352905\n",
      "93 0 0.25952643156051636\n",
      "93 100 0.26596036553382874\n",
      "94 0 0.2595115900039673\n",
      "94 100 0.2659333348274231\n",
      "95 0 0.25948476791381836\n",
      "95 100 0.2659122943878174\n",
      "96 0 0.2594357132911682\n",
      "96 100 0.2658437490463257\n",
      "97 0 0.2593241035938263\n",
      "97 100 0.2658037543296814\n",
      "98 0 0.2593109905719757\n",
      "98 100 0.26571422815322876\n",
      "99 0 0.2592777609825134\n",
      "99 100 0.26565924286842346\n"
     ]
    }
   ],
   "source": [
    "# 定义优化器\n",
    "optimizer = tf.optimizers.Adam(lr=lr)\n",
    "# 训练\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    for step, x in enumerate(train_db):\n",
    "        # [b, 28, 28] => [b, 28*28]\n",
    "        x = tf.reshape(x, [-1, 784])\n",
    "        with tf.GradientTape() as tape:\n",
    "            x_rec_logicts = autoEncoder(x)\n",
    "            rec_loss = tf.losses.binary_crossentropy(x, x_rec_logicts, from_logits=True)\n",
    "            rec_loss = tf.reduce_mean(rec_loss)\n",
    "            \n",
    "        grads = tape.gradient(rec_loss, autoEncoder.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, autoEncoder.trainable_variables))\n",
    "        \n",
    "        if step % 100 == 0:\n",
    "            print(epoch, step, float(rec_loss))\n",
    "            \n",
    "    # evaluation 评估\n",
    "    # 从test_db 取一个batchsz的数据用于测试\n",
    "    x = next(iter(test_db))\n",
    "    logits = autoEncoder(tf.reshape(x, [-1, 28*28]))\n",
    "    # 得到logits 最终是为了还原成图片，所有需要经过sigmoid()函数，变换到（0，1）的范围内\n",
    "    x_hat = tf.sigmoid(logits)\n",
    "    # 将 x_hat 的维度变换成原始图片的维度 [b, 28, 28]\n",
    "    x_hat = tf.reshape(x_hat, [-1, 28, 28])    # [b, 28*28] => [-1, 28, 28]\n",
    "    \n",
    "    # 把原来的图片拼接与生成的图片拼接在一起，用于对比，在axis=0维度上拼接\n",
    "    x_concat = tf.concat([x, x_hat], axis=0)    # [b, 28, 28] => [2*b, 28, 28]\n",
    "#     x_concat = x_hat\n",
    "    # 提取x_concat中numpy数据，然后由原来的(0, 1)范围变换为 （0，255），便于显示图片，\n",
    "    x_concat = x_concat.numpy() * 255.\n",
    "    # 转换数据类型，保存图片的一种格式\n",
    "    x_concat = x_concat.astype(np.uint8)    \n",
    "    save_images(x_concat, '/home/kukafee/workspace/picture/rec_epoch_%d.png'%epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

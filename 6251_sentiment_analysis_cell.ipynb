{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment analysis cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 对全局随机数生成种子的设置\n",
    "tf.random.set_seed(22)\n",
    "# 使用相同的参数，每次生成的随机数都相同\n",
    "np.random.seed(22)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "# startwith('2.') 这个函数用于判断tf.__version__的版本信息是否以'2.0'返回，返回True或者False\n",
    "# assert 关键字用于判断该关键字后面的表达式返回值，True则不报错，返回False则报错‘AssertionError: ’\n",
    "assert tf.__version__.startswith('2.')\n",
    "assert np.__version__.startswith('1.16.2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape:  (25000, 80)\n",
      "y_train_max:  tf.Tensor(1, shape=(), dtype=int64)\n",
      "y_train_min:  tf.Tensor(0, shape=(), dtype=int64)\n",
      "x_test:  (25000, 80)\n"
     ]
    }
   ],
   "source": [
    "batchsz = 512\n",
    "# the most frequent words\n",
    "total_words = 10000    # 设定常用的单位数目为 10000\n",
    "max_review_len = 80    # 设定每个句子中单词个数的最大值，即可以统一padding为这样的长度\n",
    "# max_review_len = 100\n",
    "embedding_len = 100    # 每个单词的编码维度，即用100维的向量表示一个单词\n",
    "\n",
    "# 载入数据, imdb 是一个关于电影评论的数据集,参数num_words=total_words 限时单词数量为total_words\n",
    "# 把超出这个范围的生僻单词视为同一个单词\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.imdb.load_data(num_words=total_words)\n",
    "# x_train: [b, 80]  把x_train中每条评论（句子） padding为统一的长度,不足的话补0，超过的截取\n",
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=max_review_len)\n",
    "# x_test:  [b, 80]  把x_test padding为统一的长度——80\n",
    "x_test = keras.preprocessing.sequence.pad_sequences(x_test, maxlen=max_review_len)\n",
    "\n",
    "# 对数据集进行切片处理\n",
    "db_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "# batch()的参数 drop_remainer 设置为 True 是丢弃最末尾的 batch可能出现不为整数的batch\n",
    "db_train = db_train.shuffle(1000).batch(batchsz, drop_remainder=True)\n",
    "db_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "db_test = db_test.batch(batchsz, drop_remainder=True)\n",
    "# 打印显示\n",
    "print('x_train shape: ', x_train.shape)\n",
    "print('y_train_max: ', tf.reduce_max(y_train))\n",
    "print('y_train_min: ', tf.reduce_min(y_train))\n",
    "print('x_test: ', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(x_train))\n",
    "# print(x_train)\n",
    "# print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义MyRNN类\n",
    "class MyRNN(keras.Model):\n",
    "    # 定义初始化方法，其中 units 参数表示在RNN网络Cell中的维度（节点数）隐含层的维度 h_dim\n",
    "    def __init__(self, units):\n",
    "        super(MyRNN, self).__init__()\n",
    "        # 建立初始化状态\n",
    "        # [b, 64] \n",
    "        self.state0 = [tf.zeros([batchsz, units])]\n",
    "        self.state1 = [tf.zeros([batchsz, units])]\n",
    "        \n",
    "#         self.state2 = [tf.zeros([batchsz, units])]\n",
    "        # embedding 层，用于数据类型的编码(嵌入表示）,第一个参数表示数据中单词数量的总数，\n",
    "        # 第二个参数表示每个单词的编码维度，\n",
    "        # 第三个单词表示每个句子的长度（全部padding为80了）\n",
    "        # [b, 80] => [b, 80, 100]\n",
    "        # transform text to embedding representation\n",
    "        self.embedding = layers.Embedding(total_words, embedding_len, input_length=max_review_len)\n",
    "        \n",
    "        # [b, 80, 100] , h_dim: 64\n",
    "        # units 参数表示Cell的隐含层的维度 h_dim\n",
    "        # dropout=0.5表示随机丢弃节点，提高效率并且降低过拟合(一般只在training时起作用)\n",
    "        # [b, 80, 100] => [b, 64]\n",
    "        self.rnn_cell0 = layers.SimpleRNNCell(units, dropout=0.5)\n",
    "        self.rnn_cell1 = layers.SimpleRNNCell(units, dropout=0.5)\n",
    "#         self.rnn_cell2 = layers.SimpleRNNCell(units, dropout=0.5)\n",
    "        \n",
    "        # 定义全连接层，用于分类，输入维度为1，即一个节点\n",
    "        # [b, 64] => [b, 1]\n",
    "        self.outlayer = layers.Dense(1)\n",
    "        \n",
    "    def call(self, inputs, training=None):    \n",
    "        \"\"\"\n",
    "        通过设置training=None，在测试时dropout失效\n",
    "        net(x) ;  net(x, training=True);  net(x, training=None)    -->  train mode\n",
    "        net(x, training=False)   -->  test mode\n",
    "        \n",
    "        \"\"\"\n",
    "        x = inputs    # [b, 80]\n",
    "        \n",
    "        x = self.embedding(x)    # [b, 80]  =>  [b, 80, 100]\n",
    "        \n",
    "        state0 = self.state0    # \n",
    "        state1 = self.state1    # \n",
    "#         state2 = self.state2\n",
    "        # [b, 80, 100]  =>  [b, 64]\n",
    "        for word in tf.unstack(x, axis=1):    # word: [b, 100]\n",
    "            # out0: [b, 64] 添加training参数，在training时进行 dropout操作\n",
    "            out0, state0 = self.rnn_cell0(word, state0, training)\n",
    "            # out1: [b, 64]\n",
    "            out1, state1 = self.rnn_cell1(out0, state1, training)\n",
    "            # out2: [b, 64]\n",
    "#             out2, state2 = self.rnn_cell1(out1, state2, training)\n",
    "        # out1 --> x   :   [b, 64]  =>  [b, 1]    \n",
    "        x = self.outlayer(out1)\n",
    "        # p(y is pos | x )\n",
    "        prob = tf.sigmoid(x)\n",
    "        \n",
    "        return prob\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "48/48 [==============================] - 8s 158ms/step - loss: 0.7005 - accuracy: 0.5087 - val_loss: 0.6842 - val_accuracy: 0.5767\n",
      "Epoch 2/5\n",
      "48/48 [==============================] - 2s 36ms/step - loss: 0.5869 - accuracy: 0.6202 - val_loss: 0.4236 - val_accuracy: 0.8088\n",
      "Epoch 3/5\n",
      "48/48 [==============================] - 2s 34ms/step - loss: 0.3696 - accuracy: 0.8235 - val_loss: 0.4226 - val_accuracy: 0.8092\n",
      "Epoch 4/5\n",
      "48/48 [==============================] - 2s 32ms/step - loss: 0.2888 - accuracy: 0.8720 - val_loss: 0.4264 - val_accuracy: 0.8258\n",
      "Epoch 5/5\n",
      "48/48 [==============================] - 2s 34ms/step - loss: 0.2216 - accuracy: 0.9090 - val_loss: 0.4885 - val_accuracy: 0.8282\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.4885 - accuracy: 0.8282\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4884813651442528, 0.8282471]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "units = 64\n",
    "# units = 150\n",
    "epochs = 5\n",
    "model = MyRNN(units)\n",
    "model.compile(optimizer = keras.optimizers.Adam(0.001),\n",
    "             loss = tf.losses.BinaryCrossentropy(),\n",
    "             metrics = ['accuracy'])\n",
    "# 训练\n",
    "model.fit(db_train, epochs=epochs, validation_data=db_test)\n",
    "# \n",
    "model.evaluate(db_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

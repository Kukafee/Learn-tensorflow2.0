{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment analysis cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 对全局随机数生成种子的设置\n",
    "tf.random.set_seed(22)\n",
    "# 使用相同的参数，每次生成的随机数都相同\n",
    "np.random.seed(22)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "# startwith('2.') 这个函数用于判断tf.__version__的版本信息是否以'2.0'开头，返回True或者False\n",
    "# assert 关键字用于判断该关键字后面的表达式返回值，True则不报错，返回False则报错‘AssertionError: ’\n",
    "assert tf.__version__.startswith('2.')\n",
    "assert np.__version__.startswith('1.16.2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape:  (25000, 80)\n",
      "y_train_max:  tf.Tensor(1, shape=(), dtype=int64)\n",
      "y_train_min:  tf.Tensor(0, shape=(), dtype=int64)\n",
      "x_test:  (25000, 80)\n"
     ]
    }
   ],
   "source": [
    "batchsz = 512\n",
    "# the most frequent words\n",
    "total_words = 10000    # 设定常用的单词数目为 10000\n",
    "max_review_len = 80    # 设定每个句子中单词个数的最大值，即可以统一padding为这样的长度\n",
    "# max_review_len = 100\n",
    "embedding_len = 100    # 每个单词的编码维度，即用100维的向量表示一个单词\n",
    "\n",
    "# 载入数据, imdb 是一个关于电影评论的数据集,参数num_words=total_words 限时单词数量为total_words\n",
    "# 把超出这个范围的生僻单词视为同一个单词\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.imdb.load_data(num_words=total_words)\n",
    "# x_train: [b, 80]  把x_train中每条评论（句子） padding为统一的长度,不足的话补0，超过的截取\n",
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=max_review_len)\n",
    "# x_test:  [b, 80]  把x_test padding为统一的长度——80\n",
    "x_test = keras.preprocessing.sequence.pad_sequences(x_test, maxlen=max_review_len)\n",
    "\n",
    "# 对数据集进行切片处理\n",
    "db_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "# batch()的参数 drop_remainer 设置为 True 是丢弃最末尾的 batch可能出现不为整数的batch\n",
    "db_train = db_train.shuffle(1000).batch(batchsz, drop_remainder=True)\n",
    "db_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "db_test = db_test.batch(batchsz, drop_remainder=True)\n",
    "# 打印显示\n",
    "print('x_train shape: ', x_train.shape)\n",
    "print('y_train_max: ', tf.reduce_max(y_train))\n",
    "print('y_train_min: ', tf.reduce_min(y_train))\n",
    "print('x_test: ', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(x_train))\n",
    "# print(x_train)\n",
    "# print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义MyRNN类\n",
    "class MyRNN(keras.Model):\n",
    "    # 定义初始化方法，其中 units 参数表示在RNN网络Cell中的维度（节点数）隐含层的维度 h_dim\n",
    "    def __init__(self, units):\n",
    "        super(MyRNN, self).__init__()\n",
    "        # 建立初始化状态\n",
    "        # [b, 64]   这里是列表\n",
    "        self.state0 = [tf.zeros([batchsz, units])]\n",
    "        self.state1 = [tf.zeros([batchsz, units])]\n",
    "        \n",
    "#         self.state2 = [tf.zeros([batchsz, units])]\n",
    "        # 添加BatchNormalization\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        \n",
    "\n",
    "        # embedding 层，用于数据类型的编码(嵌入表示）,第一个参数表示数据中单词数量的总数，\n",
    "        # 第二个参数表示每个单词的编码维度，\n",
    "        # 第三个单词表示每个句子的长度（全部padding为80了）\n",
    "        # [b, 80] => [b, 80, 100]\n",
    "        # transform text to embedding representation\n",
    "        self.embedding = layers.Embedding(total_words, embedding_len, input_length=max_review_len)\n",
    "        # 定义RNN单元\n",
    "        # [b, 80, 100] , h_dim: 64\n",
    "        # units 参数表示Cell的隐含层的维度 h_dim\n",
    "        # dropout=0.5表示随机丢弃节点，提高效率并且降低过拟合(一般只在training时起作用)\n",
    "        # [b, 80, 100] => [b, 64]\n",
    "        self.rnn_cell0 = layers.SimpleRNNCell(units, dropout=0.7)\n",
    "        self.rnn_cell1 = layers.SimpleRNNCell(units, dropout=0.7)\n",
    "#         self.rnn_cell2 = layers.SimpleRNNCell(units, dropout=0.5)\n",
    "        \n",
    "        # 定义全连接层，用于分类，输入维度为1，即一个节点\n",
    "        # [b, 64] => [b, 1]\n",
    "        \n",
    "        self.outlayer = layers.Dense(1)\n",
    "        \n",
    "    def call(self, inputs, training=None):    \n",
    "        \"\"\"\n",
    "        通过设置training=None，在测试时dropout失效\n",
    "        net(x) ; net(x, training=True) ; net(x, training=None)   -->   train mode\n",
    "        net(x, training=False)   -->   test mode\n",
    "        \n",
    "        \"\"\"\n",
    "        x = inputs    # [b, 80]\n",
    "        \n",
    "        x = self.embedding(x)    # [b, 80]  =>  [b, 80, 100]\n",
    "        \n",
    "        state0 = self.state0    # [batchsz, units]\n",
    "        state1 = self.state1    # [batchsz, units]\n",
    "#         state2 = self.state2\n",
    "        # [b, 80, 100]  =>  [b, 64]\n",
    "        for word in tf.unstack(x, axis=1):    # word: [b, 100]  * 80\n",
    "            # out0: [b, 64] 添加training参数，在training时进行 dropout操作\n",
    "            out0, state0 = self.rnn_cell0(word, state0, training)\n",
    "            # out1: [b, 64]\n",
    "            out1, state1 = self.rnn_cell1(out0, state1, training)\n",
    "            # out2: [b, 64]\n",
    "#             out2, state2 = self.rnn_cell1(out1, state2, training)\n",
    "        # out1 --> x   :   [b, 64]  =>  [b, 1]    \n",
    "        x = self.outlayer(out1)\n",
    "        # p(y is pos | x )\n",
    "        x_BN = self.bn1(x)\n",
    "        prob = tf.sigmoid(x_BN)\n",
    "        \n",
    "        return prob\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "48/48 [==============================] - 8s 162ms/step - loss: 0.7937 - accuracy: 0.5101 - val_loss: 0.8266 - val_accuracy: 0.5034\n",
      "Epoch 2/8\n",
      "48/48 [==============================] - 2s 33ms/step - loss: 0.7427 - accuracy: 0.5249 - val_loss: 0.7738 - val_accuracy: 0.5964\n",
      "Epoch 3/8\n",
      "48/48 [==============================] - 1s 31ms/step - loss: 0.5749 - accuracy: 0.6736 - val_loss: 0.4701 - val_accuracy: 0.7855\n",
      "Epoch 4/8\n",
      "48/48 [==============================] - 2s 32ms/step - loss: 0.4934 - accuracy: 0.7824 - val_loss: 0.4807 - val_accuracy: 0.7793\n",
      "Epoch 5/8\n",
      "48/48 [==============================] - 2s 31ms/step - loss: 0.4611 - accuracy: 0.8212 - val_loss: 0.4091 - val_accuracy: 0.8249\n",
      "Epoch 6/8\n",
      "48/48 [==============================] - 2s 32ms/step - loss: 0.4341 - accuracy: 0.8458 - val_loss: 0.4095 - val_accuracy: 0.8299\n",
      "Epoch 7/8\n",
      "48/48 [==============================] - 1s 30ms/step - loss: 0.4125 - accuracy: 0.8669 - val_loss: 0.4105 - val_accuracy: 0.8341\n",
      "Epoch 8/8\n",
      "48/48 [==============================] - 2s 32ms/step - loss: 0.3929 - accuracy: 0.8771 - val_loss: 0.4207 - val_accuracy: 0.8245\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.4207 - accuracy: 0.8245\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.42070302305122215, 0.8244629]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "units = 64\n",
    "# units = 150\n",
    "epochs = 8\n",
    "model = MyRNN(units)\n",
    "model.compile(optimizer = keras.optimizers.Adam(1e-3),\n",
    "             loss = tf.losses.BinaryCrossentropy(),\n",
    "             metrics = ['accuracy'])\n",
    "# 训练RNN\n",
    "model.fit(db_train, epochs=epochs, validation_data=db_test)\n",
    "# 测试评估\n",
    "model.evaluate(db_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

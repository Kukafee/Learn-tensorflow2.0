{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow2.0 可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, optimizers, Sequential,metrics\n",
    "import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "import io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 编写数据集预处理函数\n",
    "def preprocess(x, y):\n",
    "    # 把x转换为 tf.float32类型，并压缩到 [0, 1] 之间，注意：此处除以 255. (包括小数点)\n",
    "    x = tf.cast(x, dtype=tf.float32) / 255.\n",
    "    # 只需把y转换为 tf.int32即可\n",
    "    y = tf.cast(y, dtype=tf.int32)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             multiple                  200960    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             multiple                  32896     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             multiple                  8256      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             multiple                  2080      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             multiple                  330       \n",
      "=================================================================\n",
      "Total params: 244,522\n",
      "Trainable params: 244,522\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "0 loss: 2.3940629959106445\n",
      "test acc:  17.047275641025642 %\n",
      "(128, 784)\n",
      "100 loss: 0.5174907445907593\n",
      "test acc:  79.54727564102564 %\n",
      "(128, 784)\n",
      "200 loss: 0.43536344170570374\n",
      "test acc:  80.78926282051282 %\n",
      "(128, 784)\n",
      "300 loss: 0.2943505048751831\n",
      "test acc:  83.61378205128204 %\n",
      "(128, 784)\n",
      "400 loss: 0.3945080041885376\n",
      "test acc:  83.60376602564102 %\n",
      "(128, 784)\n",
      "500 loss: 0.44371265172958374\n",
      "test acc:  84.47516025641025 %\n",
      "(128, 784)\n",
      "600 loss: 0.4480273425579071\n",
      "test acc:  83.62379807692307 %\n",
      "(128, 784)\n",
      "700 loss: 0.4439612329006195\n",
      "test acc:  85.34655448717949 %\n",
      "(128, 784)\n",
      "800 loss: 0.415263295173645\n",
      "test acc:  85.57692307692307 %\n",
      "(128, 784)\n",
      "900 loss: 0.2605874538421631\n",
      "test acc:  85.95753205128204 %\n",
      "(128, 784)\n",
      "1000 loss: 0.3151707053184509\n",
      "test acc:  84.6854967948718 %\n",
      "(128, 784)\n",
      "1100 loss: 0.3530539572238922\n",
      "test acc:  85.40665064102564 %\n",
      "(128, 784)\n",
      "1200 loss: 0.4886952042579651\n",
      "test acc:  86.29807692307693 %\n",
      "(128, 784)\n",
      "1300 loss: 0.29977184534072876\n",
      "test acc:  85.99759615384616 %\n",
      "(128, 784)\n",
      "1400 loss: 0.3002206087112427\n",
      "test acc:  87.20953525641025 %\n",
      "(128, 784)\n",
      "1500 loss: 0.25114816427230835\n",
      "test acc:  86.92908653846155 %\n",
      "(128, 784)\n",
      "1600 loss: 0.27070188522338867\n",
      "test acc:  87.44991987179486 %\n",
      "(128, 784)\n",
      "1700 loss: 0.26537394523620605\n",
      "test acc:  87.38982371794873 %\n",
      "(128, 784)\n",
      "1800 loss: 0.300653338432312\n",
      "test acc:  87.28966346153845 %\n",
      "(128, 784)\n",
      "1900 loss: 0.3118376135826111\n",
      "test acc:  87.47996794871796 %\n",
      "(128, 784)\n",
      "2000 loss: 0.2600822448730469\n",
      "test acc:  87.43990384615384 %\n",
      "(128, 784)\n",
      "2100 loss: 0.29057812690734863\n",
      "test acc:  87.17948717948718 %\n",
      "(128, 784)\n",
      "2200 loss: 0.24378615617752075\n",
      "test acc:  86.94911858974359 %\n",
      "(128, 784)\n",
      "2300 loss: 0.29801657795906067\n",
      "test acc:  86.8389423076923 %\n",
      "(128, 784)\n",
      "2400 loss: 0.2540847063064575\n",
      "test acc:  87.51001602564102 %\n",
      "(128, 784)\n",
      "2500 loss: 0.19741599261760712\n",
      "test acc:  87.53004807692307 %\n",
      "(128, 784)\n",
      "2600 loss: 0.3084273636341095\n",
      "test acc:  87.07932692307693 %\n",
      "(128, 784)\n",
      "2700 loss: 0.31628936529159546\n",
      "test acc:  87.84054487179486 %\n",
      "(128, 784)\n",
      "2800 loss: 0.21016547083854675\n",
      "test acc:  87.33974358974359 %\n",
      "(128, 784)\n",
      "2900 loss: 0.19237549602985382\n",
      "test acc:  87.5400641025641 %\n",
      "(128, 784)\n",
      "3000 loss: 0.2893272340297699\n",
      "test acc:  87.42988782051282 %\n",
      "(128, 784)\n",
      "3100 loss: 0.3780040740966797\n",
      "test acc:  87.46995192307693 %\n",
      "(128, 784)\n",
      "3200 loss: 0.17813074588775635\n",
      "test acc:  87.95072115384616 %\n",
      "(128, 784)\n",
      "3300 loss: 0.33031752705574036\n",
      "test acc:  88.08092948717949 %\n",
      "(128, 784)\n",
      "3400 loss: 0.20707178115844727\n",
      "test acc:  87.91065705128204 %\n",
      "(128, 784)\n",
      "3500 loss: 0.1506950408220291\n",
      "test acc:  87.99078525641025 %\n",
      "(128, 784)\n",
      "3600 loss: 0.2451196014881134\n",
      "test acc:  88.43149038461539 %\n",
      "(128, 784)\n",
      "3700 loss: 0.32856476306915283\n",
      "test acc:  88.00080128205127 %\n",
      "(128, 784)\n",
      "3800 loss: 0.17899614572525024\n",
      "test acc:  87.99078525641025 %\n",
      "(128, 784)\n",
      "3900 loss: 0.2336510419845581\n",
      "test acc:  88.44150641025641 %\n",
      "(128, 784)\n",
      "4000 loss: 0.17923703789710999\n",
      "test acc:  87.65024038461539 %\n",
      "(128, 784)\n",
      "4100 loss: 0.3262108266353607\n",
      "test acc:  88.57171474358975 %\n",
      "(128, 784)\n",
      "4200 loss: 0.36392244696617126\n",
      "test acc:  88.34134615384616 %\n",
      "(128, 784)\n",
      "4300 loss: 0.2371121197938919\n",
      "test acc:  87.75040064102564 %\n",
      "(128, 784)\n",
      "4400 loss: 0.2345830202102661\n",
      "test acc:  88.54166666666666 %\n",
      "(128, 784)\n",
      "4500 loss: 0.1913926899433136\n",
      "test acc:  88.2411858974359 %\n",
      "(128, 784)\n",
      "4600 loss: 0.22185559570789337\n",
      "test acc:  87.79046474358975 %\n",
      "(128, 784)\n"
     ]
    }
   ],
   "source": [
    "def plot_to_image(figure):\n",
    "    '''\n",
    "    Converts the matplotlib plot specified by 'figure' to a PNG image and returns it. The supplied \n",
    "    figure is closed and inaccessible after this call.\n",
    "    '''\n",
    "    # Save the plot to a PNG in memory.\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    # Closing the figure prevents it from being displayed directly inside the notebook.\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "    # Convert PNG buffer to TF image\n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    # Add the batch dimension\n",
    "    image = tf.expand_dims(image, 0)    \n",
    "    return image\n",
    "def image_grid(images):\n",
    "    '''Return a 5*5 grid of the MNIST images as a matplotlib figure'''\n",
    "    # Create a figure to contain the plot.\n",
    "    figure = plt.figure(figsize=(10, 10))\n",
    "    for i in range(25):\n",
    "        # start next subplot.\n",
    "        plt.subplot(5, 5, i+1, title='name')\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(images[i], cmap=plt.cm.binary)\n",
    "        \n",
    "    return figure\n",
    "\n",
    "batchsz = 128\n",
    "(x, y), (x_val, y_val) = datasets.fashion_mnist.load_data()\n",
    "db = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "db = db.map(preprocess).shuffle(60000).batch(batchsz).repeat(10)\n",
    "\n",
    "db_val = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "db_val = db_val.map(preprocess).batch(batchsz, drop_remainder=True)\n",
    "\n",
    "\n",
    "network = Sequential([   \n",
    "    layers.Dense(256, activation=tf.nn.relu),    # [b, 784] => [b, 256]\n",
    "    layers.Dense(128, activation=tf.nn.relu),    # [b, 256] => [b, 128]\n",
    "    layers.Dense(64, activation=tf.nn.relu),     # [b, 128] => [b, 64]\n",
    "    layers.Dense(32, activation=tf.nn.relu),     # [b, 64] => [b, 32]\n",
    "    layers.Dense(10)                             # [b, 32] => [b, 10]\n",
    "])\n",
    "\n",
    "# network = Sequential([   \n",
    "#     layers.Dense(684, activation=tf.nn.relu),    \n",
    "#     layers.Dense(654, activation=tf.nn.relu),    \n",
    "#     layers.Dense(624, activation=tf.nn.relu),    \n",
    "#     layers.Dense(594, activation=tf.nn.relu),    \n",
    "#     layers.Dense(40, activation=tf.nn.relu),    \n",
    "#     layers.Dense(20, activation=tf.nn.relu),\n",
    "#     layers.Dense(15, activation=tf.nn.relu),\n",
    "#     layers.Dense(10)                           \n",
    "# ])\n",
    "\n",
    "\n",
    "network.build(input_shape=(None, 28*28))\n",
    "network.summary()\n",
    "\n",
    "optimizer = optimizers.Adam(lr=0.001)\n",
    "\n",
    "######################################\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "log_dir = '/home/kukafee/workspace/TensorBoard/' + current_time\n",
    "# 创建writer\n",
    "summary_writer = tf.summary.create_file_writer(log_dir)\n",
    "######################################\n",
    "\n",
    "# get x from (x, y)\n",
    "sample_img = next(iter(db))[0]\n",
    "# get first image instance \n",
    "sample_img = sample_img[0]\n",
    "sample_img = tf.reshape(sample_img, [1, 28, 28, 1])\n",
    "with summary_writer.as_default():\n",
    "    tf.summary.image(\"Training sample:\", sample_img, step=0)\n",
    "    \n",
    "for step, (x, y) in enumerate(db):\n",
    "    with tf.GradientTape() as tape:\n",
    "        x = tf.reshape(x, (-1, 28*28))\n",
    "        out = network(x)\n",
    "        \n",
    "        y_onehot = tf.one_hot(y, depth=10)\n",
    "        loss = tf.reduce_mean(tf.losses.categorical_crossentropy(y_onehot, out, from_logits=True))\n",
    "        \n",
    "    grads = tape.gradient(loss, network.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, network.trainable_variables))\n",
    "    \n",
    "    if step % 100 == 0:\n",
    "        print(step, 'loss:', float(loss))\n",
    "        with summary_writer.as_default():\n",
    "            tf.summary.scalar('train-loss', float(loss), step=step)\n",
    "            \n",
    "        # evaluate\n",
    "        total_correct = 0\n",
    "        total_num = 0\n",
    "        for x, y in db_val:\n",
    "            x = tf.reshape(x, [-1, 28*28])\n",
    "            out = network(x)  # [b, 10]\n",
    "            pred = tf.cast(tf.argmax(out, axis=1),tf.int32)\n",
    "            correct = tf.equal(pred, y)\n",
    "            correct = tf.reduce_sum(tf.cast(correct, dtype=tf.int32))\n",
    "\n",
    "            total_correct += int(correct)   # 使用int() 函数把tensor类型转化为numpy的int类型\n",
    "            total_num += x.shape[0]    # x.shape[0] 是测试集中测试样本的个数\n",
    "\n",
    "        acc = total_correct / total_num * 100\n",
    "        print('test acc: ',acc,'%')\n",
    "        \n",
    "        print(x.shape)\n",
    "        val_images = x[:25]\n",
    "        val_images = tf.reshape(val_images,[-1, 28, 28, 1])\n",
    "        with summary_writer.as_default():\n",
    "            tf.summary.scalar('test-acc', float(total_correct/total_num), step=step)\n",
    "            # 单个显示\n",
    "            tf.summary.image(\"val-onebyon-images:\", val_images, max_outputs=25, step=step)\n",
    "            # 在一个画板上一起显示多个图片\n",
    "#             val_images = tf.reshape(val_images, [-1, 28, 28])\n",
    "#             figure = image_grid(val_images)\n",
    "#             tf.summary.image('val-images: ', plot_to_image(figure), step=step)\n",
    "            \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

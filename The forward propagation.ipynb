{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The forward propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-alpha0\n",
      "sys.version_info(major=3, minor=6, micro=7, releaselevel='final', serial=0)\n",
      "matplotlib 3.1.0\n",
      "numpy 1.16.4\n",
      "pandas 0.24.2\n",
      "sklearn 0.21.2\n",
      "tensorflow 2.0.0-alpha0\n",
      "tensorflow.python.keras.api._v2.keras 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "print(tf.__version__)\n",
    "print(sys.version_info)\n",
    "for module in mpl, np, pd, sklearn, tf, keras:\n",
    "    print(module.__name__, module.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['KMP_DUPLICATE_LIB_OK']='TRUE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n",
      "(60000, 28, 28) (60000,)\n",
      "<dtype: 'float32'> <dtype: 'int32'>\n",
      "tf.Tensor(0.0, shape=(), dtype=float32) tf.Tensor(1.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0, shape=(), dtype=int32) tf.Tensor(9, shape=(), dtype=int32)\n",
      "<BatchDataset shapes: ((None, 28, 28), (None,)), types: (tf.float32, tf.int32)>\n",
      "batch: (128, 28, 28) (128,)\n",
      "0 loss 0.3739185929298401\n",
      "100 loss 0.20279736816883087\n",
      "200 loss 0.18764355778694153\n",
      "300 loss 0.15630705654621124\n",
      "400 loss 0.17131371796131134\n",
      "test acc:  0.1531\n",
      "0 loss 0.1506539285182953\n",
      "100 loss 0.14658518135547638\n",
      "200 loss 0.15247231721878052\n",
      "300 loss 0.13330957293510437\n",
      "400 loss 0.15170340240001678\n",
      "test acc:  0.2013\n",
      "0 loss 0.13165995478630066\n",
      "100 loss 0.12952342629432678\n",
      "200 loss 0.13429725170135498\n",
      "300 loss 0.11866581439971924\n",
      "400 loss 0.13745377957820892\n",
      "test acc:  0.2553\n",
      "0 loss 0.11854919046163559\n",
      "100 loss 0.11742846667766571\n",
      "200 loss 0.12138597667217255\n",
      "300 loss 0.1081489771604538\n",
      "400 loss 0.12697237730026245\n",
      "test acc:  0.3071\n",
      "0 loss 0.10888797044754028\n",
      "100 loss 0.10837298631668091\n",
      "200 loss 0.11171770095825195\n",
      "300 loss 0.10023868083953857\n",
      "400 loss 0.11886084079742432\n",
      "test acc:  0.3501\n",
      "0 loss 0.1014614924788475\n",
      "100 loss 0.10134626924991608\n",
      "200 loss 0.10430636256933212\n",
      "300 loss 0.09408785402774811\n",
      "400 loss 0.11234717071056366\n",
      "test acc:  0.3889\n",
      "0 loss 0.09562104195356369\n",
      "100 loss 0.09576521813869476\n",
      "200 loss 0.09843523800373077\n",
      "300 loss 0.0891299769282341\n",
      "400 loss 0.10704101622104645\n",
      "test acc:  0.4186\n",
      "0 loss 0.09093306958675385\n",
      "100 loss 0.09118956327438354\n",
      "200 loss 0.09358297288417816\n",
      "300 loss 0.0850466787815094\n",
      "400 loss 0.10262738168239594\n",
      "test acc:  0.4494\n",
      "0 loss 0.08705833554267883\n",
      "100 loss 0.08735281974077225\n",
      "200 loss 0.08949965238571167\n",
      "300 loss 0.08165981620550156\n",
      "400 loss 0.0988650768995285\n",
      "test acc:  0.471\n",
      "0 loss 0.08373554795980453\n",
      "100 loss 0.08407849073410034\n",
      "200 loss 0.08601267635822296\n",
      "300 loss 0.078802190721035\n",
      "400 loss 0.09562395513057709\n",
      "test acc:  0.4931\n",
      "0 loss 0.08086507022380829\n",
      "100 loss 0.08126897364854813\n",
      "200 loss 0.08300863951444626\n",
      "300 loss 0.07631301879882812\n",
      "400 loss 0.09277751296758652\n",
      "test acc:  0.5131\n",
      "0 loss 0.07834864407777786\n",
      "100 loss 0.07885460555553436\n",
      "200 loss 0.08038673549890518\n",
      "300 loss 0.07410570979118347\n",
      "400 loss 0.0902431458234787\n",
      "test acc:  0.53\n",
      "0 loss 0.0761321410536766\n",
      "100 loss 0.076726533472538\n",
      "200 loss 0.07808082550764084\n",
      "300 loss 0.07214301079511642\n",
      "400 loss 0.08799419552087784\n",
      "test acc:  0.5431\n",
      "0 loss 0.07416710257530212\n",
      "100 loss 0.07483886927366257\n",
      "200 loss 0.07601650059223175\n",
      "300 loss 0.07037798315286636\n",
      "400 loss 0.08597797155380249\n",
      "test acc:  0.5573\n",
      "0 loss 0.072405606508255\n",
      "100 loss 0.07315544039011002\n",
      "200 loss 0.07415620982646942\n",
      "300 loss 0.06879771500825882\n",
      "400 loss 0.08414358645677567\n",
      "test acc:  0.57\n",
      "0 loss 0.07079605758190155\n",
      "100 loss 0.07163573056459427\n",
      "200 loss 0.07246558368206024\n",
      "300 loss 0.06737428903579712\n",
      "400 loss 0.08244960010051727\n",
      "test acc:  0.5798\n",
      "0 loss 0.06932054460048676\n",
      "100 loss 0.07026097923517227\n",
      "200 loss 0.07092620432376862\n",
      "300 loss 0.06607560068368912\n",
      "400 loss 0.08088143914937973\n",
      "test acc:  0.5923\n",
      "0 loss 0.06798499077558517\n",
      "100 loss 0.0689958855509758\n",
      "200 loss 0.06952037662267685\n",
      "300 loss 0.06487787514925003\n",
      "400 loss 0.07943486422300339\n",
      "test acc:  0.6042\n",
      "0 loss 0.06675630062818527\n",
      "100 loss 0.06783364713191986\n",
      "200 loss 0.06823839247226715\n",
      "300 loss 0.06376807391643524\n",
      "400 loss 0.07810315489768982\n",
      "test acc:  0.6129\n",
      "0 loss 0.0656154677271843\n",
      "100 loss 0.06676201522350311\n",
      "200 loss 0.06704863160848618\n",
      "300 loss 0.06273956596851349\n",
      "400 loss 0.07685916870832443\n",
      "test acc:  0.6236\n",
      "0 loss 0.06455053389072418\n",
      "100 loss 0.0657590851187706\n",
      "200 loss 0.0659400075674057\n",
      "300 loss 0.06177784129977226\n",
      "400 loss 0.07570093870162964\n",
      "test acc:  0.6331\n",
      "0 loss 0.06356695294380188\n",
      "100 loss 0.06482533365488052\n",
      "200 loss 0.06489653140306473\n",
      "300 loss 0.060872387140989304\n",
      "400 loss 0.07461199909448624\n",
      "test acc:  0.6414\n",
      "0 loss 0.06265456229448318\n",
      "100 loss 0.06396479159593582\n",
      "200 loss 0.06391962617635727\n",
      "300 loss 0.06001695990562439\n",
      "400 loss 0.07358627021312714\n",
      "test acc:  0.6489\n",
      "0 loss 0.06180224567651749\n",
      "100 loss 0.06316576153039932\n",
      "200 loss 0.06299781054258347\n",
      "300 loss 0.05921534448862076\n",
      "400 loss 0.07262295484542847\n",
      "test acc:  0.6584\n",
      "0 loss 0.06100432947278023\n",
      "100 loss 0.06241004914045334\n",
      "200 loss 0.062133438885211945\n",
      "300 loss 0.058459825813770294\n",
      "400 loss 0.07171471416950226\n",
      "test acc:  0.6679\n",
      "0 loss 0.06024874001741409\n",
      "100 loss 0.061694394797086716\n",
      "200 loss 0.06131779029965401\n",
      "300 loss 0.0577472448348999\n",
      "400 loss 0.0708576887845993\n",
      "test acc:  0.6738\n",
      "0 loss 0.0595332607626915\n",
      "100 loss 0.06102200597524643\n",
      "200 loss 0.06054572016000748\n",
      "300 loss 0.05706767365336418\n",
      "400 loss 0.07004441320896149\n",
      "test acc:  0.6804\n",
      "0 loss 0.05885114520788193\n",
      "100 loss 0.06038782745599747\n",
      "200 loss 0.05981346219778061\n",
      "300 loss 0.05642211437225342\n",
      "400 loss 0.06927336007356644\n",
      "test acc:  0.6873\n",
      "0 loss 0.05820218473672867\n",
      "100 loss 0.05978991836309433\n",
      "200 loss 0.059118688106536865\n",
      "300 loss 0.05580633878707886\n",
      "400 loss 0.06853310763835907\n",
      "test acc:  0.6919\n",
      "0 loss 0.05758313089609146\n",
      "100 loss 0.05922352522611618\n",
      "200 loss 0.05846042558550835\n",
      "300 loss 0.05522096902132034\n",
      "400 loss 0.06782989948987961\n",
      "test acc:  0.6972\n",
      "0 loss 0.056991301476955414\n",
      "100 loss 0.05868161469697952\n",
      "200 loss 0.057830702513456345\n",
      "300 loss 0.05466900020837784\n",
      "400 loss 0.06715868413448334\n",
      "test acc:  0.7017\n",
      "0 loss 0.05642770975828171\n",
      "100 loss 0.05816107988357544\n",
      "200 loss 0.05722980573773384\n",
      "300 loss 0.05414297431707382\n",
      "400 loss 0.06652028113603592\n",
      "test acc:  0.707\n",
      "0 loss 0.055891253054142\n",
      "100 loss 0.057661402970552444\n",
      "200 loss 0.05665469169616699\n",
      "300 loss 0.05363648384809494\n",
      "400 loss 0.06591123342514038\n",
      "test acc:  0.7112\n",
      "0 loss 0.05537514016032219\n",
      "100 loss 0.05718241259455681\n",
      "200 loss 0.05610257387161255\n",
      "300 loss 0.053151119500398636\n",
      "400 loss 0.06532837450504303\n",
      "test acc:  0.7166\n",
      "0 loss 0.05487992241978645\n",
      "100 loss 0.056722380220890045\n",
      "200 loss 0.0555758997797966\n",
      "300 loss 0.05268531292676926\n",
      "400 loss 0.06477192789316177\n",
      "test acc:  0.7214\n",
      "0 loss 0.054403889924287796\n",
      "100 loss 0.05627722665667534\n",
      "200 loss 0.05507133528590202\n",
      "300 loss 0.052240680903196335\n",
      "400 loss 0.06423606723546982\n",
      "test acc:  0.7257\n",
      "0 loss 0.053944118320941925\n",
      "100 loss 0.05584751442074776\n",
      "200 loss 0.05458387732505798\n",
      "300 loss 0.051812607795000076\n",
      "400 loss 0.06372378766536713\n",
      "test acc:  0.7296\n",
      "0 loss 0.053502269089221954\n",
      "100 loss 0.055435698479413986\n",
      "200 loss 0.054115910083055496\n",
      "300 loss 0.05139944702386856\n",
      "400 loss 0.06323288381099701\n",
      "test acc:  0.7336\n",
      "0 loss 0.0530756339430809\n",
      "100 loss 0.055039048194885254\n",
      "200 loss 0.05366910248994827\n",
      "300 loss 0.051002513617277145\n",
      "400 loss 0.06276165693998337\n",
      "test acc:  0.7374\n",
      "0 loss 0.05266249179840088\n",
      "100 loss 0.054654091596603394\n",
      "200 loss 0.05324043706059456\n",
      "300 loss 0.05061763525009155\n",
      "400 loss 0.062308646738529205\n",
      "test acc:  0.7418\n",
      "0 loss 0.0522611141204834\n",
      "100 loss 0.054279766976833344\n",
      "200 loss 0.052827198058366776\n",
      "300 loss 0.05024446174502373\n",
      "400 loss 0.061870772391557693\n",
      "test acc:  0.745\n",
      "0 loss 0.051872171461582184\n",
      "100 loss 0.05391756445169449\n",
      "200 loss 0.05242884159088135\n",
      "300 loss 0.04988393932580948\n",
      "400 loss 0.0614485964179039\n",
      "test acc:  0.7488\n",
      "0 loss 0.05149470642209053\n",
      "100 loss 0.05356348305940628\n",
      "200 loss 0.05204414576292038\n",
      "300 loss 0.04953331500291824\n",
      "400 loss 0.061041880398988724\n",
      "test acc:  0.7523\n",
      "0 loss 0.05112943798303604\n",
      "100 loss 0.053218960762023926\n",
      "200 loss 0.05167366936802864\n",
      "300 loss 0.04919097572565079\n",
      "400 loss 0.06064491719007492\n",
      "test acc:  0.7559\n",
      "0 loss 0.05077538639307022\n",
      "100 loss 0.05288463085889816\n",
      "200 loss 0.051314253360033035\n",
      "300 loss 0.0488596186041832\n",
      "400 loss 0.0602569580078125\n",
      "test acc:  0.7588\n",
      "0 loss 0.05043100193142891\n",
      "100 loss 0.052561234682798386\n",
      "200 loss 0.05096525698900223\n",
      "300 loss 0.048539094626903534\n",
      "400 loss 0.05987973138689995\n",
      "test acc:  0.7626\n",
      "0 loss 0.05009637027978897\n",
      "100 loss 0.05224649980664253\n",
      "200 loss 0.05062800645828247\n",
      "300 loss 0.04822862520813942\n",
      "400 loss 0.0595158226788044\n",
      "test acc:  0.7658\n",
      "0 loss 0.04977115988731384\n",
      "100 loss 0.05194144695997238\n",
      "200 loss 0.050301384180784225\n",
      "300 loss 0.04792814329266548\n",
      "400 loss 0.05916255712509155\n",
      "test acc:  0.7687\n",
      "0 loss 0.04945395514369011\n",
      "100 loss 0.05164610221982002\n",
      "200 loss 0.04998411610722542\n",
      "300 loss 0.04763560742139816\n",
      "400 loss 0.058818213641643524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc:  0.7716\n",
      "0 loss 0.04914478957653046\n",
      "100 loss 0.0513569600880146\n",
      "200 loss 0.04967530071735382\n",
      "300 loss 0.04735064506530762\n",
      "400 loss 0.058481864631175995\n",
      "test acc:  0.7733\n",
      "0 loss 0.04884248971939087\n",
      "100 loss 0.05107574909925461\n",
      "200 loss 0.04937392845749855\n",
      "300 loss 0.04707380011677742\n",
      "400 loss 0.05815477296710014\n",
      "test acc:  0.7754\n",
      "0 loss 0.04854652285575867\n",
      "100 loss 0.05080237239599228\n",
      "200 loss 0.04907980561256409\n",
      "300 loss 0.046804215759038925\n",
      "400 loss 0.057836245745420456\n",
      "test acc:  0.7773\n",
      "0 loss 0.048256468027830124\n",
      "100 loss 0.05053632706403732\n",
      "200 loss 0.04879232496023178\n",
      "300 loss 0.046542853116989136\n",
      "400 loss 0.05752643942832947\n",
      "test acc:  0.7789\n",
      "0 loss 0.04797373339533806\n",
      "100 loss 0.050277501344680786\n",
      "200 loss 0.04851140081882477\n",
      "300 loss 0.04628737270832062\n",
      "400 loss 0.05722472071647644\n",
      "test acc:  0.7804\n",
      "0 loss 0.04769743233919144\n",
      "100 loss 0.050023049116134644\n",
      "200 loss 0.048237428069114685\n",
      "300 loss 0.04603815823793411\n",
      "400 loss 0.05693094804883003\n",
      "test acc:  0.7821\n",
      "0 loss 0.04742921143770218\n",
      "100 loss 0.04977414757013321\n",
      "200 loss 0.04796983674168587\n",
      "300 loss 0.04579486697912216\n",
      "400 loss 0.05664396286010742\n",
      "test acc:  0.7841\n",
      "0 loss 0.04716796427965164\n",
      "100 loss 0.049531012773513794\n",
      "200 loss 0.04770883172750473\n",
      "300 loss 0.04555834084749222\n",
      "400 loss 0.056362323462963104\n",
      "test acc:  0.7855\n",
      "0 loss 0.046913161873817444\n",
      "100 loss 0.04929463565349579\n",
      "200 loss 0.047452133148908615\n",
      "300 loss 0.04532769322395325\n",
      "400 loss 0.05608830973505974\n",
      "test acc:  0.7869\n",
      "0 loss 0.04666457325220108\n",
      "100 loss 0.049063730984926224\n",
      "200 loss 0.04720030352473259\n",
      "300 loss 0.04510245844721794\n",
      "400 loss 0.055822283029556274\n",
      "test acc:  0.7883\n",
      "0 loss 0.04642029479146004\n",
      "100 loss 0.048838984221220016\n",
      "200 loss 0.04695381596684456\n",
      "300 loss 0.04488217085599899\n",
      "400 loss 0.05556114390492439\n",
      "test acc:  0.7903\n",
      "0 loss 0.04618097469210625\n",
      "100 loss 0.04861849173903465\n",
      "200 loss 0.046712808310985565\n",
      "300 loss 0.044667359441518784\n",
      "400 loss 0.05530590936541557\n",
      "test acc:  0.7922\n",
      "0 loss 0.04594796150922775\n",
      "100 loss 0.04840081185102463\n",
      "200 loss 0.046476926654577255\n",
      "300 loss 0.04445798322558403\n",
      "400 loss 0.05505537986755371\n",
      "test acc:  0.7941\n",
      "0 loss 0.04572043940424919\n",
      "100 loss 0.04818783327937126\n",
      "200 loss 0.046245865523815155\n",
      "300 loss 0.04425348713994026\n",
      "400 loss 0.05480987951159477\n",
      "test acc:  0.7958\n",
      "0 loss 0.04549818113446236\n",
      "100 loss 0.04797930270433426\n",
      "200 loss 0.04601909965276718\n",
      "300 loss 0.04405323788523674\n",
      "400 loss 0.05456848070025444\n",
      "test acc:  0.7974\n",
      "0 loss 0.04528048634529114\n",
      "100 loss 0.04777548089623451\n",
      "200 loss 0.04579780623316765\n",
      "300 loss 0.0438571535050869\n",
      "400 loss 0.05433086305856705\n",
      "test acc:  0.7982\n",
      "0 loss 0.04506685212254524\n",
      "100 loss 0.04757580906152725\n",
      "200 loss 0.04558125138282776\n",
      "300 loss 0.043664634227752686\n",
      "400 loss 0.05409734323620796\n",
      "test acc:  0.7995\n",
      "0 loss 0.044856809079647064\n",
      "100 loss 0.0473792664706707\n",
      "200 loss 0.0453699566423893\n",
      "300 loss 0.04347614198923111\n",
      "400 loss 0.0538678877055645\n",
      "test acc:  0.8008\n",
      "0 loss 0.044648729264736176\n",
      "100 loss 0.0471857525408268\n",
      "200 loss 0.045163244009017944\n",
      "300 loss 0.043290767818689346\n",
      "400 loss 0.053642839193344116\n",
      "test acc:  0.8018\n",
      "0 loss 0.04444452375173569\n",
      "100 loss 0.04699527099728584\n",
      "200 loss 0.04495852440595627\n",
      "300 loss 0.043109577149152756\n",
      "400 loss 0.05342205613851547\n",
      "test acc:  0.803\n",
      "0 loss 0.04424426704645157\n",
      "100 loss 0.04680836573243141\n",
      "200 loss 0.04475855454802513\n",
      "300 loss 0.042931683361530304\n",
      "400 loss 0.05320552736520767\n",
      "test acc:  0.8041\n",
      "0 loss 0.044048063457012177\n",
      "100 loss 0.046624016016721725\n",
      "200 loss 0.04456209018826485\n",
      "300 loss 0.04275640845298767\n",
      "400 loss 0.05299230292439461\n",
      "test acc:  0.8057\n",
      "0 loss 0.04385533928871155\n",
      "100 loss 0.04644226282835007\n",
      "200 loss 0.04436954855918884\n",
      "300 loss 0.04258444905281067\n",
      "400 loss 0.05278228595852852\n",
      "test acc:  0.8064\n",
      "0 loss 0.04366595298051834\n",
      "100 loss 0.04626351222395897\n",
      "200 loss 0.044179584830999374\n",
      "300 loss 0.042415864765644073\n",
      "400 loss 0.052576445043087006\n",
      "test acc:  0.8077\n",
      "0 loss 0.04348050057888031\n",
      "100 loss 0.04608767107129097\n",
      "200 loss 0.04399311542510986\n",
      "300 loss 0.0422501340508461\n",
      "400 loss 0.05237395688891411\n",
      "test acc:  0.8097\n",
      "0 loss 0.043299600481987\n",
      "100 loss 0.045914165675640106\n",
      "200 loss 0.04380941018462181\n",
      "300 loss 0.042088307440280914\n",
      "400 loss 0.052175819873809814\n",
      "test acc:  0.8106\n",
      "0 loss 0.043121106922626495\n",
      "100 loss 0.04574275761842728\n",
      "200 loss 0.043628938496112823\n",
      "300 loss 0.0419294573366642\n",
      "400 loss 0.051981158554553986\n",
      "test acc:  0.8124\n",
      "0 loss 0.04294642060995102\n",
      "100 loss 0.04557356983423233\n",
      "200 loss 0.04345039278268814\n",
      "300 loss 0.041773077100515366\n",
      "400 loss 0.051789384335279465\n",
      "test acc:  0.8139\n",
      "0 loss 0.04277442768216133\n",
      "100 loss 0.045406877994537354\n",
      "200 loss 0.04327485337853432\n",
      "300 loss 0.04161917045712471\n",
      "400 loss 0.05160091444849968\n",
      "test acc:  0.8148\n",
      "0 loss 0.04260508716106415\n",
      "100 loss 0.04524276778101921\n",
      "200 loss 0.043102651834487915\n",
      "300 loss 0.041467685252428055\n",
      "400 loss 0.05141612887382507\n",
      "test acc:  0.8158\n",
      "0 loss 0.04243846982717514\n",
      "100 loss 0.04508119076490402\n",
      "200 loss 0.04293479397892952\n",
      "300 loss 0.04131802171468735\n",
      "400 loss 0.05123426392674446\n",
      "test acc:  0.8167\n",
      "0 loss 0.04227348417043686\n",
      "100 loss 0.044921617954969406\n",
      "200 loss 0.04277034103870392\n",
      "300 loss 0.04117036610841751\n",
      "400 loss 0.051055509597063065\n",
      "test acc:  0.818\n",
      "0 loss 0.0421118326485157\n",
      "100 loss 0.04476507753133774\n",
      "200 loss 0.042607974261045456\n",
      "300 loss 0.04102588817477226\n",
      "400 loss 0.05087975785136223\n",
      "test acc:  0.8192\n",
      "0 loss 0.041952528059482574\n",
      "100 loss 0.04460994154214859\n",
      "200 loss 0.04244818538427353\n",
      "300 loss 0.04088376834988594\n",
      "400 loss 0.05070624500513077\n",
      "test acc:  0.8202\n",
      "0 loss 0.04179447889328003\n",
      "100 loss 0.04445634409785271\n",
      "200 loss 0.04229087755084038\n",
      "300 loss 0.04074370115995407\n",
      "400 loss 0.050534240901470184\n",
      "test acc:  0.8207\n",
      "0 loss 0.041638828814029694\n",
      "100 loss 0.04430307075381279\n",
      "200 loss 0.04213584214448929\n",
      "300 loss 0.040605418384075165\n",
      "400 loss 0.05036422610282898\n",
      "test acc:  0.8211\n",
      "0 loss 0.04148558899760246\n",
      "100 loss 0.04415161907672882\n",
      "200 loss 0.041983358561992645\n",
      "300 loss 0.04046958312392235\n",
      "400 loss 0.050196655094623566\n",
      "test acc:  0.8221\n",
      "0 loss 0.041334547102451324\n",
      "100 loss 0.04400248825550079\n",
      "200 loss 0.041833486407995224\n",
      "300 loss 0.04033572971820831\n",
      "400 loss 0.050031907856464386\n",
      "test acc:  0.8231\n",
      "0 loss 0.04118582233786583\n",
      "100 loss 0.04385536536574364\n",
      "200 loss 0.0416865199804306\n",
      "300 loss 0.040203750133514404\n",
      "400 loss 0.049869049340486526\n",
      "test acc:  0.8242\n",
      "0 loss 0.04103929549455643\n",
      "100 loss 0.04371078684926033\n",
      "200 loss 0.041541144251823425\n",
      "300 loss 0.04007342457771301\n",
      "400 loss 0.04970734566450119\n",
      "test acc:  0.8257\n",
      "0 loss 0.0408940389752388\n",
      "100 loss 0.043568164110183716\n",
      "200 loss 0.041397951543331146\n",
      "300 loss 0.03994538635015488\n",
      "400 loss 0.04954852908849716\n",
      "test acc:  0.8274\n",
      "0 loss 0.04075097292661667\n",
      "100 loss 0.043427348136901855\n",
      "200 loss 0.041256289929151535\n",
      "300 loss 0.039818715304136276\n",
      "400 loss 0.04939130321145058\n",
      "test acc:  0.8287\n",
      "0 loss 0.040609486401081085\n",
      "100 loss 0.04328916594386101\n",
      "200 loss 0.04111715406179428\n",
      "300 loss 0.03969354182481766\n",
      "400 loss 0.0492362380027771\n",
      "test acc:  0.8292\n",
      "0 loss 0.04046998545527458\n",
      "100 loss 0.04315223917365074\n",
      "200 loss 0.0409802570939064\n",
      "300 loss 0.03957017883658409\n",
      "400 loss 0.0490829236805439\n",
      "test acc:  0.8299\n",
      "0 loss 0.04033200815320015\n",
      "100 loss 0.04301674664020538\n",
      "200 loss 0.040845442563295364\n",
      "300 loss 0.03944843262434006\n",
      "400 loss 0.048931874334812164\n",
      "test acc:  0.8308\n",
      "0 loss 0.04019530490040779\n",
      "100 loss 0.0428820438683033\n",
      "200 loss 0.04071202129125595\n",
      "300 loss 0.039328306913375854\n",
      "400 loss 0.048782289028167725\n",
      "test acc:  0.8318\n",
      "0 loss 0.040060002356767654\n",
      "100 loss 0.04274865984916687\n",
      "200 loss 0.04058045148849487\n",
      "300 loss 0.03920993208885193\n",
      "400 loss 0.04863402992486954\n",
      "test acc:  0.8328\n",
      "0 loss 0.03992601856589317\n",
      "100 loss 0.0426173098385334\n",
      "200 loss 0.040451470762491226\n",
      "300 loss 0.039093200117349625\n",
      "400 loss 0.04848714545369148\n",
      "test acc:  0.8338\n",
      "0 loss 0.03979356214404106\n",
      "100 loss 0.042487502098083496\n",
      "200 loss 0.040324900299310684\n",
      "300 loss 0.03897818177938461\n",
      "400 loss 0.04834199696779251\n",
      "test acc:  0.8348\n",
      "0 loss 0.039662133902311325\n",
      "100 loss 0.0423588752746582\n",
      "200 loss 0.04020062834024429\n",
      "300 loss 0.03886451572179794\n",
      "400 loss 0.04819998890161514\n",
      "test acc:  0.8352\n",
      "0 loss 0.039532024413347244\n",
      "100 loss 0.04223151132464409\n",
      "200 loss 0.04007767513394356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 loss 0.03875236585736275\n",
      "400 loss 0.04805907607078552\n",
      "test acc:  0.8358\n"
     ]
    }
   ],
   "source": [
    "(x, y), (x_test, y_test) = datasets.mnist.load_data()\n",
    "print(x.shape, y.shape)\n",
    "\n",
    "x = tf.convert_to_tensor(x, dtype=tf.float32) / 255.\n",
    "y = tf.convert_to_tensor(y, dtype=tf.int32)\n",
    "\n",
    "x_test = tf.convert_to_tensor(x_test, dtype=tf.float32) / 255.\n",
    "y_test = tf.convert_to_tensor(y_test, dtype=tf.int32)\n",
    "\n",
    "print(x.shape, y.shape)\n",
    "print(x.dtype, y.dtype)\n",
    "print(tf.reduce_min(x), tf.reduce_max(x))\n",
    "print(tf.reduce_min(y), tf.reduce_max(y))\n",
    "\n",
    "train_db = tf.data.Dataset.from_tensor_slices((x,y)).batch(128)\n",
    "test_db = tf.data.Dataset.from_tensor_slices((x_test,y_test)).batch(128)\n",
    "print(train_db)\n",
    "\n",
    "train_iter = iter(train_db)\n",
    "sample = next(train_iter)\n",
    "print('batch:', sample[0].shape, sample[1].shape)\n",
    "\n",
    "w1 = tf.Variable(tf.random.truncated_normal([784, 256], stddev = 0.1))\n",
    "b1 = tf.Variable(tf.zeros([256]))\n",
    "w2 = tf.Variable(tf.random.truncated_normal([256,128], stddev = 0.1))\n",
    "b2 = tf.Variable(tf.zeros([128]))\n",
    "w3 = tf.Variable(tf.random.truncated_normal([128,10], stddev = 0.1))\n",
    "b3 = tf.Variable(tf.zeros([10]))\n",
    "lr = 1e-3\n",
    "\n",
    "for epoch in range(100):\n",
    "    for step, (x, y) in enumerate(train_db):\n",
    "        x = tf.reshape(x, [-1, 28*28])\n",
    "        with tf.GradientTape() as tape:\n",
    "            h1 = x@w1 + tf.broadcast_to(b1, [x.shape[0], 256])\n",
    "            h1 = tf.nn.relu(h1)\n",
    "            h2 = h1@w2 + b2\n",
    "            h2 = tf.nn.relu(h2)\n",
    "\n",
    "            out = h2@w3 + b3\n",
    "            y_onehot = tf.one_hot(y, depth=10)\n",
    "\n",
    "            loss = tf.square(y_onehot - out)\n",
    "            loss = tf.reduce_mean(loss)\n",
    "\n",
    "        grads = tape.gradient(loss, [w1, b1, w2, b2, w3, b3])\n",
    "    #     w1 = w1 - lr * grads[0]\n",
    "    #     b1 = b1 - lr * grads[1]\n",
    "    #     w2 = w2 - lr * grads[2]\n",
    "    #     b2 = b2 - lr * grads[3]\n",
    "    #     w3 = w3 - lr * grads[4]\n",
    "    #     b3 = b3 - lr * grads[5]\n",
    "        w1.assign_sub(lr * grads[0])\n",
    "        b1.assign_sub(lr * grads[1])\n",
    "        w2.assign_sub(lr * grads[2])\n",
    "        b2.assign_sub(lr * grads[3])\n",
    "        w3.assign_sub(lr * grads[4])\n",
    "        b3.assign_sub(lr * grads[5])\n",
    "\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            print(step, 'loss', float(loss))\n",
    "    \n",
    "    total_correct, total_num = 0,0\n",
    "    for step, (x, y) in enumerate(test_db):\n",
    "        x = tf.reshape(x, [-1, 28*28])\n",
    "        h1 = tf.nn.relu(x@w1 + b1)\n",
    "        h2 = tf.nn.relu(h1@w2 + b2)\n",
    "        out = h2@w3 + b3\n",
    "        \n",
    "        prob = tf.nn.softmax(out, axis=1)\n",
    "        pred = tf.argmax(prob, axis=1)\n",
    "        pred = tf.cast(pred, dtype=tf.int32)\n",
    "        \n",
    "        correct = tf.cast(tf.equal(pred, y), dtype=tf.int32)\n",
    "        correct = tf.reduce_sum(correct)\n",
    "        \n",
    "        total_correct += int(correct)\n",
    "        total_num += x.shape[0]\n",
    "        \n",
    "        acc = total_correct / total_num\n",
    "        \n",
    "    print('test acc: ', acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
